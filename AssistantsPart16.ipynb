{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 16\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time  # Used for time-related functions\n",
    "import threading  # Used for creating and managing threads\n",
    "\n",
    "# Third-party library imports\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from IPython.display import display, Markdown, clear_output  # Used for displaying content in Jupyter Notebooks\n",
    "\n",
    "import base64  # Used for encoding and decoding binary data\n",
    "import requests  # Used for making HTTP requests\n",
    "import markdown2  # Used for converting Markdown to HTML\n",
    "from IPython.display import display, HTML  # Used for displaying HTML content in Jupyter Notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our custom event handler class that inherits from AssistantEventHandler for streaming assistant output.\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\"\"\"\n",
    "        # Print the created text to the console\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        # Append the created text to the results list\n",
    "        self.results.append(text)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Print the delta value (partial text) to the console\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        # Append the delta value to the results list\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\"\"\"\n",
    "        # Print the type of the tool call to the console\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            # Check if there is an input in the code interpreter delta\n",
    "            if delta.code_interpreter.input:\n",
    "                # Print the input to the console\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "                # Append the input to the results list\n",
    "                self.results.append(delta.code_interpreter.input)\n",
    "            # Check if there are outputs in the code interpreter delta\n",
    "            if delta.code_interpreter.outputs:\n",
    "                # Print a label for outputs to the console\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "                # Iterate over each output and handle logs specifically\n",
    "                for output in delta.code_interpreter.outputs or []:\n",
    "                    if output.type == \"logs\":\n",
    "                        # Print the logs to the console\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                        # Append the logs to the results list\n",
    "                        self.results.append(output.logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_OhOeXCXyY3ly7zKBKZYEFQkb', created_at=1719317311, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",  # Instructions for the assistant.\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}],  # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    \n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-aKwzrvGKa8phcqCgDxq5HtYQ', bytes=13519, created_at=1719317311, filename='penguins_size.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose.\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),  # Open the file in binary read mode.\n",
    "    purpose='assistants'  # Specify the purpose of the file upload.\n",
    ")\n",
    "\n",
    "# Print the details of the uploaded file to check its properties.\n",
    "print(assistant_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_OhOeXCXyY3ly7zKBKZYEFQkb', created_at=1719317311, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-aKwzrvGKa8phcqCgDxq5HtYQ']), file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "# Update the assistant to add tools and tool resources.\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,  # Use the assistant's ID.\n",
    "    tools=[{\"type\": \"code_interpreter\"}],  # Add the code interpreter capability to the assistant.\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]  # Link the uploaded file to the code interpreter tool.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the details of the updated assistant to check its properties.\n",
    "print(assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant tool > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file\n",
      "file_path = '/mnt/data/file-aKwzrvGKa8phcqCgDxq5HtYQ'\n",
      "penguins_data = pd.read_csv(file_path)\n",
      "\n",
      "# Display the first few rows and summary of the dataframe\n",
      "penguins_data.head(), penguins_data.describe()\n",
      "assistant text > The file `penguins_size.csv` contains data about different species of penguins. Here's a summary of its contents:\n",
      "\n",
      "### Columns:\n",
      "1. **species**: The species of the penguin (e.g., Adelie).\n",
      "2. **island**: The island where the penguin was observed (e.g., Torgersen).\n",
      "3. **culmen_length_mm**: Length of the culmen (beak) in millimeters.\n",
      "4. **culmen_depth_mm**: Depth of the culmen (beak) in millimeters.\n",
      "5. **flipper_length_mm**: Length of the flipper in millimeters.\n",
      "6. **body_mass_g**: Body mass in grams.\n",
      "7. **sex**: Sex of the penguin (e.g., MALE, FEMALE).\n",
      "\n",
      "### Summary Statistics:\n",
      "- **culmen_length_mm**:\n",
      "  - Count: 342 entries\n",
      "  - Mean: 43.92 mm\n",
      "  - Standard Deviation: 5.46 mm\n",
      "  - Min: 32.1 mm\n",
      "  - Max: 59.6 mm\n",
      "\n",
      "- **culmen_depth_mm**:\n",
      "  - Count: 342 entries\n",
      "  - Mean: 17.15 mm\n",
      "  - Standard Deviation: 1.97 mm\n",
      "  - Min: 13.1 mm\n",
      "  - Max: 21.5 mm\n",
      "\n",
      "- **flipper_length_mm**:\n",
      "  - Count: 342 entries\n",
      "  - Mean: 200.92 mm\n",
      "  - Standard Deviation: 14.06 mm\n",
      "  - Min: 172.0 mm\n",
      "  - Max: 231.0 mm\n",
      "\n",
      "- **body_mass_g**:\n",
      "  - Count: 342 entries\n",
      "  - Mean: 4201.75 g\n",
      "  - Standard Deviation: 801.95 g\n",
      "  - Min: 2700.0 g\n",
      "  - Max: 6300.0 g\n",
      "\n",
      "### Sample Data:\n",
      "Here are the first few rows of the dataset:\n",
      "| species | island | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
      "|---------|--------|------------------|-----------------|-------------------|-------------|-------|\n",
      "| Adelie  | Torgersen | 39.1             | 18.7             | 181.0               | 3750.0      | MALE  |\n",
      "| Adelie  | Torgersen | 39.5             | 17.4             | 186.0               | 3800.0      | FEMALE|\n",
      "| Adelie  | Torgersen | 40.3             | 18.0             | 195.0               | 3250.0      | FEMALE|\n",
      "| Adelie  | Torgersen | NaN              | NaN              | NaN                 | NaN         | NaN   |\n",
      "| Adelie  | Torgersen | 36.7             | 19.3             | 193.0               | 3450.0      | FEMALE|\n",
      "\n",
      "Some cells contain missing values (denoted as `NaN`).\n",
      "\n",
      "If you have any specific questions or need further analysis, please let me know!"
     ]
    }
   ],
   "source": [
    "# Create a new assistant thread with an initial user message.\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Stream the assistant's response to the thread.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Use the thread's ID.\n",
    "    assistant_id=assistant.id,  # Use the assistant's ID.\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",  # Provide instructions to the assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Output\n",
    "What if we want to format the markdown output? There are two ways to do it. The \"easy\" way is to just let the output render without streaming and format it afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The file `penguins_size.csv` contains data on 344 penguins with the following columns:\n",
       "\n",
       "1. **species**: The species of the penguin (categorical).\n",
       "2. **island**: The island where the penguin was observed (categorical).\n",
       "3. **culmen_length_mm**: The length of the culmen (bill) in millimeters (numerical, float).\n",
       "4. **culmen_depth_mm**: The depth of the culmen in millimeters (numerical, float).\n",
       "5. **flipper_length_mm**: The length of the flipper in millimeters (numerical, float).\n",
       "6. **body_mass_g**: The body mass in grams (numerical, float).\n",
       "7. **sex**: The sex of the penguin (categorical).\n",
       "\n",
       "### Summary:\n",
       "- The dataset has **344 entries**.\n",
       "- There are some missing values in **culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g**, and **sex** columns.\n",
       "- Numerical columns: `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g`.\n",
       "- Categorical columns: `species`, `island`, `sex`.\n",
       "\n",
       "### Sample Data:\n",
       "Here are the first few rows of the dataset to give an impression of the values:\n",
       "| species | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
       "|---------|-----------|------------------|-----------------|-------------------|-------------|-------|\n",
       "| Adelie  | Torgersen | 39.1             | 18.7            | 181.0             | 3750.0      | MALE  |\n",
       "| Adelie  | Torgersen | 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE|\n",
       "| Adelie  | Torgersen | 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE|\n",
       "| Adelie  | Torgersen | NaN              | NaN             | NaN               | NaN         | NaN   |\n",
       "| Adelie  | Torgersen | 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE|\n",
       "\n",
       "If you need further analysis or specific operations on this dataset, please let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new assistant thread with an initial user message.\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create and poll a new run for the assistant thread to get the response.\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id  # Specify the assistant ID.\n",
    ")\n",
    "\n",
    "# Retrieve all messages from the thread using the run ID.\n",
    "messages = list(client.beta.threads.messages.list(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    run_id=run.id  # Specify the run ID.\n",
    "))\n",
    "\n",
    "# Extract the content from the first message in the retrieved messages.\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations  # Extract annotations from the message content.\n",
    "citations = []  # Initialize an empty list to store citations.\n",
    "\n",
    "# Process each annotation to replace the text with indexed references and gather citations.\n",
    "for index, annotation in enumerate(annotations):\n",
    "    # Replace the annotated text with an indexed reference in the message content.\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    # Check if there is a file citation in the annotation.\n",
    "    file_citation = getattr(annotation, \"file_citation\", None)\n",
    "    if file_citation:\n",
    "        # Retrieve the cited file's details using its file ID.\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        # Append the citation with the indexed reference and file name to the citations list.\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "# Display the processed message content with indexed references using Markdown.\n",
    "display(Markdown(message_content.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hard\"  (but more user-friendly) way is to stream the output and update the display while streaming to show the formatted text. This is what ChatGPT does when you use it. This will require modifying our event handler to be more streamlined, formatting output, and updating our display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of `penguins_size.csv`\n",
       "\n",
       "The dataset consists of penguin measurements including species information and various physical attributes such as culmen length, culmen depth, flipper length, and body mass. Below is a statistical summary and a small sample of the data.\n",
       "\n",
       "#### Statistical Summary\n",
       "\n",
       "| Statistic         | Culmen Length (mm) | Culmen Depth (mm) | Flipper Length (mm) | Body Mass (g)  |\n",
       "|-------------------|--------------------|-------------------|---------------------|----------------|\n",
       "| Count             | 342                | 342               | 342                 | 342            |\n",
       "| Mean              | 43.92              | 17.15             | 200.92              | 4201.75        |\n",
       "| Std Dev           | 5.46               | 1.97              | 14.06               | 801.95         |\n",
       "| Min               | 32.10              | 13.10             | 172.00              | 2700.00        |\n",
       "| 25th Percentile   | 39.23              | 15.60             | 190.00              | 3550.00        |\n",
       "| Median (50th %ile)| 44.45              | 17.30             | 197.00              | 4050.00        |\n",
       "| 75th Percentile   | 48.50              | 18.70             | 213.00              | 4750.00        |\n",
       "| Max               | 59.60              | 21.50             | 231.00              | 6300.00        |\n",
       "\n",
       "#### Sample Data\n",
       "\n",
       "| Species | Island    | Culmen Length (mm) | Culmen Depth (mm) | Flipper Length (mm) | Body Mass (g) | Sex   |\n",
       "|---------|-----------|--------------------|-------------------|---------------------|---------------|-------|\n",
       "| Adelie  | Torgersen | 39.1               | 18.7              | 181.0               | 3750.0        | MALE  |\n",
       "| Adelie  | Torgersen | 39.5               | 17.4              | 186.0               | 3800.0        | FEMALE|\n",
       "| Adelie  | Torgersen | 40.3               | 18.0              | 195.0               | 3250.0        | FEMALE|\n",
       "| Adelie  | Torgersen | NaN                | NaN               | NaN                 | NaN           | NaN   |\n",
       "| Adelie  | Torgersen | 36.7               | 19.3              | 193.0               | 3450.0        | FEMALE|\n",
       "\n",
       "This summary and sample data provide a clear overview of the dataset, highlighting essential statistics and giving a glimpse into the data structure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        self.results.append(delta.value)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "# Create a new assistant thread with an initial user message.\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv. With at least one small table of data. Make the information well formatted and easy to read.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Stream the assistant's response to the thread.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",  # Provide instructions to the assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-CXzGmzUz78HYY8vOHucDCzm7', bytes=43599, created_at=1719317366, filename='daily-bike-share.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose.\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),  # Open the file in binary read mode.\n",
    "    purpose='assistants'  # Specify the purpose of the file upload.\n",
    ")\n",
    "\n",
    "# Print the details of the uploaded file to check its properties.\n",
    "print(thread_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_yvjtV29Eibl5UqR6pQWciG9C', created_at=1719317368, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread with an initial user message requesting a summary of the file.\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the daily-bike-share.csv file.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the details of the created thread to check its properties.\n",
    "print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_yvjtV29Eibl5UqR6pQWciG9C', created_at=1719317368, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-CXzGmzUz78HYY8vOHucDCzm7']), file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# Update the existing thread to add tool resources, specifically linking the uploaded file.\n",
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,  # Use the ID of the existing thread.\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]  # Link the uploaded file to the code interpreter tool.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the details of the updated thread to check its properties.\n",
    "print(updated_thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it against a new assistant and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_mCoidHXknJZXBbiA5qZfWSrY', created_at=1719317369, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant Using Thread Data', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant Using Thread Data\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "thread_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",  # Instructions for the assistant.\n",
    "    \n",
    "    name=\"Code Interpreter Assistant Using Thread Data\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}],  # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(thread_assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(thread_assistant.name)  # Print the name of the assistant.\n",
    "print(thread_assistant.metadata)  # Print the metadata of the assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The dataset consists of 731 entries with 13 columns. Here's a summary of the columns:\n",
       "\n",
       "### Columns and Data Types\n",
       "1. **day**: Integer (non-null)\n",
       "2. **mnth**: Integer (non-null)\n",
       "3. **year**: Integer (non-null)\n",
       "4. **season**: Integer (non-null)\n",
       "5. **holiday**: Integer (non-null)\n",
       "6. **weekday**: Integer (non-null)\n",
       "7. **workingday**: Integer (non-null)\n",
       "8. **weathersit**: Integer (non-null)\n",
       "9. **temp**: Float (non-null)\n",
       "10. **atemp**: Float (non-null)\n",
       "11. **hum**: Float (non-null)\n",
       "12. **windspeed**: Float (non-null)\n",
       "13. **rentals**: Integer (non-null)\n",
       "\n",
       "### Summary Statistics\n",
       "For the numeric columns, here are some key statistics:\n",
       "- **day**:\n",
       "  - Mean: 15.74\n",
       "  - Std: 8.81\n",
       "  - Min: 1\n",
       "  - Max: 31\n",
       "- **mnth**:\n",
       "  - Mean: 6.52\n",
       "  - Std: 3.45\n",
       "  - Min: 1\n",
       "  - Max: 12\n",
       "- **year**:\n",
       "  - Mean: 2011.5\n",
       "  - Std: 0.5\n",
       "  - Min: 2011\n",
       "  - Max: 2012\n",
       "- **season**:\n",
       "  - Mean: 2.5\n",
       "  - Std: 1.11\n",
       "  - Min: 1\n",
       "  - Max: 4\n",
       "- **holiday**:\n",
       "  - Mean: 0.03\n",
       "  - Std: 0.17\n",
       "  - Min: 0\n",
       "  - Max: 1\n",
       "- **weekday**:\n",
       "  - Mean: 3.0\n",
       "  - Std: 2.0\n",
       "  - Min: 0\n",
       "  - Max: 6\n",
       "- **workingday**:\n",
       "  - Mean: 0.68\n",
       "  - Std: 0.47\n",
       "  - Min: 0\n",
       "  - Max: 1\n",
       "- **weathersit**:\n",
       "  - Mean: 1.4\n",
       "  - Std: 0.54\n",
       "  - Min: 1\n",
       "  - Max: 3\n",
       "- **temp**:\n",
       "  - Mean: 0.495\n",
       "  - Std: 0.183\n",
       "  - Min: 0.059\n",
       "  - Max: 0.861\n",
       "- **atemp**:\n",
       "  - Mean: 0.474\n",
       "  - Std: 0.163\n",
       "  - Min: 0.079\n",
       "  - Max: 0.841\n",
       "- **hum**:\n",
       "  - Mean: 0.628\n",
       "  - Std: 0.142\n",
       "  - Min: 0.000\n",
       "  - Max: 0.973\n",
       "- **windspeed**:\n",
       "  - Mean: 0.190\n",
       "  - Std: 0.077\n",
       "  - Min: 0.022\n",
       "  - Max: 0.507\n",
       "- **rentals**:\n",
       "  - Mean: 848.18\n",
       "  - Std: 686.62\n",
       "  - Min: 2\n",
       "  - Max: 3410\n",
       "\n",
       "### Memory Usage\n",
       "- The DataFrame uses approximately 74.4 KB of memory.\n",
       "\n",
       "The dataset includes various metrics related to bike rentals, such as the day, month, year, season, whether it was a holiday, the weekday, whether it was a working day, the weather situation, temperature, \"feels-like\" temperature, humidity, wind speed, and the total number of rentals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stream the output from the assistant.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=updated_thread.id,  # Use the ID of the updated thread.\n",
    "    assistant_id=thread_assistant.id,  # Use the ID of the newly created assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler to process events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Results from files in Assistants and Threads\n",
    "\n",
    "Let's see what happens if we use an assistant with a file and a thread with a file together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_r2QHpzFRud96eEGHHHwHO2qS', created_at=1719317386, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread with an initial user message requesting a summary of two files.\n",
    "super_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Give me a summary of the penguins-size.csv and daily-bike-share.csv files. \"\n",
    "                \"Make the information well formatted and easy to read.\"\n",
    "            )\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the details of the created thread to check its properties.\n",
    "print(super_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_r2QHpzFRud96eEGHHHwHO2qS', created_at=1719317386, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-CXzGmzUz78HYY8vOHucDCzm7']), file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# Update the newly created thread to add tool resources, specifically linking the uploaded file.\n",
    "super_updated_thread = client.beta.threads.update(\n",
    "    thread_id=super_thread.id,  # Use the ID of the newly created thread.\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]  # Link the uploaded file to the code interpreter tool.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the details of the updated thread to check its properties.\n",
    "print(super_updated_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the summary of the two datasets: **penguins-size.csv** and **daily-bike-share.csv**\n",
       "\n",
       "### 1. penguins-size.csv\n",
       "\n",
       "**General Information:**\n",
       "- **Total Entries:** 344\n",
       "- **Total Columns:** 7\n",
       "\n",
       "**Columns Detail:**\n",
       "1. **species**\n",
       "   - **Data Type:** Object\n",
       "   - **Non-Null Count:** 344\n",
       "   - **Unique Values:** 3 (Adelie, Chinstrap, Gentoo)\n",
       "2. **island**\n",
       "   - **Data Type:** Object\n",
       "   - **Non-Null Count:** 344\n",
       "   - **Unique Values:** 3 (Torgersen, Biscoe, Dream)\n",
       "3. **culmen_length_mm**\n",
       "   - **Data Type:** Float64\n",
       "   - **Non-Null Count:** 342\n",
       "   - **Mean:** 43.92\n",
       "   - **Standard Deviation:** 5.46\n",
       "   - **Minimum:** 32.10\n",
       "   - **Maximum:** 59.60\n",
       "4. **culmen_depth_mm**\n",
       "   - **Data Type:** Float64\n",
       "   - **Non-Null Count:** 342\n",
       "   - **Mean:** 17.15\n",
       "   - **Standard Deviation:** 1.97\n",
       "   - **Minimum:** 13.10\n",
       "   - **Maximum:** 21.50\n",
       "5. **flipper_length_mm**\n",
       "   - **Data Type:** Float64\n",
       "   - **Non-Null Count:** 342\n",
       "   - **Mean:** 200.92\n",
       "   - **Standard Deviation:** 14.06\n",
       "   - **Minimum:** 172.00\n",
       "   - **Maximum:** 231.00\n",
       "6. **body_mass_g**\n",
       "   - **Data Type:** Float64\n",
       "   - **Non-Null Count:** 342\n",
       "   - **Mean:** 4201.75\n",
       "   - **Standard Deviation:** 801.95\n",
       "   - **Minimum:** 2700.00\n",
       "   - **Maximum:** 6300.00\n",
       "7. **sex**\n",
       "   - **Data Type:** Object\n",
       "   - **Non-Null Count:** 334\n",
       "   - **Unique Values:** 3 (MALE, FEMALE, .) \n",
       "\n",
       "### 2. daily-bike-share.csv\n",
       "\n",
       "**General Information:**\n",
       "- **Total Entries:** 731\n",
       "- **Total Columns:** 13\n",
       "\n",
       "**Columns Detail:**\n",
       "1. **day**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 15.74\n",
       "   - **Standard Deviation:** 8.81\n",
       "   - **Minimum:** 1\n",
       "   - **Maximum:** 31\n",
       "2. **mnth**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 6.52\n",
       "   - **Standard Deviation:** 3.45\n",
       "   - **Minimum:** 1\n",
       "   - **Maximum:** 12\n",
       "3. **year**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 2011.50\n",
       "   - **Standard Deviation:** 0.50\n",
       "   - **Minimum:** 2011\n",
       "   - **Maximum:** 2012\n",
       "4. **season**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 2.50\n",
       "   - **Standard Deviation:** 1.11\n",
       "   - **Minimum:** 1\n",
       "   - **Maximum:** 4\n",
       "5. **holiday**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 0.03\n",
       "   - **Standard Deviation:** 0.17\n",
       "   - **Minimum:** 0\n",
       "   - **Maximum:** 1\n",
       "6. **weekday**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 2.99\n",
       "   - **Standard Deviation:** 2.00\n",
       "   - **Minimum:** 0\n",
       "   - **Maximum:** 6\n",
       "7. **workingday**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 0.68\n",
       "   - **Standard Deviation:** 0.47\n",
       "   - **Minimum:** 0\n",
       "   - **Maximum:** 1\n",
       "8. **weathersit**\n",
       "   - **Data Type:** Int64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 1.42\n",
       "   - **Standard Deviation:** 0.64\n",
       "   - **Minimum:** 1\n",
       "   - **Maximum:** 3\n",
       "9. **temp**\n",
       "   - **Data Type:** Float64\n",
       "   - **Non-Null Count:** 731\n",
       "   - **Mean:** 0.50\n",
       "   - **Standard Deviation:** 0.18\n",
       "   - **Minimum:** 0.02\n",
       "   - **Maximum:** 0.86\n",
       "10. **atemp**\n",
       "    - **Data Type:** Float64\n",
       "    - **Non-Null Count:** 731\n",
       "    - **Mean:** 0.50\n",
       "    - **Standard Deviation:** 0.16\n",
       "    - **Minimum:** 0.10\n",
       "    - **Maximum:** 0.84\n",
       "11. **hum**\n",
       "    - **Data Type:** Float64\n",
       "    - **Non-Null Count:** 731\n",
       "    - **Mean:** 0.62\n",
       "    - **Standard Deviation:** 0.14\n",
       "    - **Minimum:** 0.00\n",
       "    - **Maximum:** 0.97\n",
       "12. **windspeed**\n",
       "    - **Data Type:** Float64\n",
       "    - **Non-Null Count:** 731\n",
       "    - **Mean:** 0.19\n",
       "    - **Standard Deviation:** 0.08\n",
       "    - **Minimum:** 0.02\n",
       "    - **Maximum:** 0.51\n",
       "13. **rentals**\n",
       "    - **Data Type:** Int64\n",
       "    - **Non-Null Count:** 731\n",
       "    - **Mean:** 848.18\n",
       "    - **Standard Deviation:** 686.62\n",
       "    - **Minimum:** 2\n",
       "    - **Maximum:** 3410\n",
       "\n",
       "These summaries include the mean, standard deviation, min, and max values for numerical columns as well as the unique values and most frequent values for categorical columns."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stream the output from the assistant.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=super_updated_thread.id,  # Use the ID of the updated thread.\n",
    "    assistant_id=assistant.id,  # Use the ID of the assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler to process events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Results Output\n",
    "\n",
    "We may also have images produced as well from the Code Interpreter output. Handling this can be tricky and getting it in the right sequence is pretty difficult. Here is some sample code that will assist but I don't pretend to be good at the interface stuff. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>It appears there are no non-numeric values in the numerical columns, which is good. However, we still face issues plotting the data.</p>\n",
       "\n",
       "<p>Since there are no visible anomalies, to tackle the problem efficiently, I will systematically reverify the steps:</p>\n",
       "\n",
       "<ol>\n",
       "<li>Coerce data to numeric types.</li>\n",
       "<li>Drop NaN values.</li>\n",
       "<li>Plot using PairPlot.</li>\n",
       "</ol>\n",
       "\n",
       "<p>Let's attempt this procedure again in a fresh manner.</p>\n",
       "<p>It appears I forgot to import the NumPy library. Let me import it and run the check again.</p>\n",
       "<p>The first 20 entries of each numerical column look fine, consisting of valid floating-point numbers or <code>NaN</code> values. However, the issue might be deeper or involving unusual non-visible characters.</p>\n",
       "\n",
       "<p>Here, I will inspect the entire dataset without displaying it, to ensure there are no hidden anomalies causing our error.</p>\n",
       "\n",
       "<p>I'll run a complete check and mention if any non-numeric issue surfaces.</p>\n",
       "<p>It appears the problem persists, probably due to unrecognizable or unsupported values in the columns. To pinpoint the exact source of the issue, we can conduct a deep inspection of the dataset, focusing on examples that may contain anomalies. Specifically, we'll check for rows introducing non-numeric or irregular entries that might be causing the issue.</p>\n",
       "\n",
       "<p>Let's inspect several entries of the columns to identify potential problematic values.</p>\n",
       "<p>The data types for the columns appear to be correctly assigned, with the numerical columns being <code>float64</code>. The issue could arise from non-standard numeric values or extra spaces/characters.</p>\n",
       "\n",
       "<p>To ensure that our data only contains valid numeric entries, we’ll re-clean the data by stripping any leading/trailing spaces and coercing again any invalid entries. We can also convert any potential non-numeric placeholders to <code>NaN</code> before dropping them.</p>\n",
       "\n",
       "<p>Let's clean the data and attempt the visualization again.</p>\n",
       "<p>The unique values for the numerical columns appear to be correctly recognized as numbers, so there is no visible issue with their types from this summary. Nevertheless, the issue might still be present due to some hidden discrepancies. Let’s verify the data types directly and identify any potential anomalies. Once verified, we’ll clean any remaining issues and retry the visualization.</p>\n",
       "\n",
       "<p>First, let's verify the data types of the columns.</p>\n",
       "<p>It seems we are still encountering issues when creating the pair plot due to potential invalid data entries. Let's perform a more detailed check to identify the issue. Specifically, we can inspect the unique values of the numerical columns to verify their data types.</p>\n",
       "<p>It appears that there's an issue with the dataset, likely due to some non-numeric values being included in our numerical columns. To fix this, we'll clean the data to ensure only valid numerical entries are kept before reattempting the pair plot.</p>\n",
       "\n",
       "<p>Let's clean the data and try creating the pair plot again.</p>\n",
       "<p>The <code>penguins_size.csv</code> dataset contains measurements of various penguin species. The dataset includes columns for species, island, culmen length (mm), culmen depth (mm), flipper length (mm), body mass (g), and sex. Here is a small table showcasing the first few records from the dataset:</p>\n",
       "\n",
       "<table>\n",
       "<thead>\n",
       "<tr>\n",
       "  <th>species</th>\n",
       "  <th>island</th>\n",
       "  <th>culmen<em>length</em>mm</th>\n",
       "  <th>culmen<em>depth</em>mm</th>\n",
       "  <th>flipper<em>length</em>mm</th>\n",
       "  <th>body<em>mass</em>g</th>\n",
       "  <th>sex</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "  <td>Adelie</td>\n",
       "  <td>Torgersen</td>\n",
       "  <td>39.1</td>\n",
       "  <td>18.7</td>\n",
       "  <td>181.0</td>\n",
       "  <td>3750.0</td>\n",
       "  <td>MALE</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Adelie</td>\n",
       "  <td>Torgersen</td>\n",
       "  <td>39.5</td>\n",
       "  <td>17.4</td>\n",
       "  <td>186.0</td>\n",
       "  <td>3800.0</td>\n",
       "  <td>FEMALE</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Adelie</td>\n",
       "  <td>Torgersen</td>\n",
       "  <td>40.3</td>\n",
       "  <td>18.0</td>\n",
       "  <td>195.0</td>\n",
       "  <td>3250.0</td>\n",
       "  <td>FEMALE</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Adelie</td>\n",
       "  <td>Torgersen</td>\n",
       "  <td>NaN</td>\n",
       "  <td>NaN</td>\n",
       "  <td>NaN</td>\n",
       "  <td>NaN</td>\n",
       "  <td>NaN</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Adelie</td>\n",
       "  <td>Torgersen</td>\n",
       "  <td>36.7</td>\n",
       "  <td>19.3</td>\n",
       "  <td>193.0</td>\n",
       "  <td>3450.0</td>\n",
       "  <td>FEMALE</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "\n",
       "<p>Next, let's generate a visualization to showcase some aspect of the data. I'll create a pair plot of the numerical features to help visualize relationships between the features.</p>\n",
       "<p>Alright, let's start by examining the contents of the file <code>penguins_size.csv</code>. I'll load and display a snippet of the data, then provide a summary along with a small table and a visualization.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a thread to send a message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a one paragraph summary of the file penguins_size.csv. With at least one small table of data and one visualization.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=assistant_thread.id, run_id=run.id))\n",
    "\n",
    "content_blocks = []\n",
    "\n",
    "# Process each message\n",
    "for message in messages:\n",
    "    # Process each content block in the message\n",
    "    for content_block in message.content:\n",
    "        if content_block.type == 'text':\n",
    "            text_content = content_block.text\n",
    "            annotations = text_content.annotations\n",
    "            citations = []\n",
    "            for index, annotation in enumerate(annotations):\n",
    "                # Replace the text with a footnote\n",
    "                text_content.value = text_content.value.replace(annotation.text, f' [{index}]')\n",
    "                # Gather citations based on annotation attributes\n",
    "                if hasattr(annotation, 'file_citation'):\n",
    "                    file_citation = annotation.file_citation\n",
    "                    cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                    citations.append(f'[{index}] {file_citation.quote} from {cited_file.filename}')\n",
    "                elif hasattr(annotation, 'file_path'):\n",
    "                    file_path = annotation.file_path\n",
    "                    cited_file = client.files.retrieve(file_path.file_id)\n",
    "                    citations.append(f'[{index}] Click <here> to download {cited_file.filename}')\n",
    "            # Add footnotes to the end of the message before displaying to user\n",
    "            text_content.value += '\\n' + '\\n'.join(citations)\n",
    "            # Convert Markdown to HTML and append to content_blocks\n",
    "            content_blocks.append(markdown2.markdown(text_content.value, extras=[\"tables\"]))\n",
    "\n",
    "        elif content_block.type == 'image_file':\n",
    "            image_file = content_block.image_file\n",
    "            file_info = client.files.retrieve(image_file.file_id)\n",
    "            image_content = client.files.content(file_info.id).content\n",
    "            image_base64 = base64.b64encode(image_content).decode('utf-8')\n",
    "            # Append the image HTML to content_blocks\n",
    "            content_blocks.append(f'<img src=\"data:image/png;base64,{image_base64}\" width=\"700\" height=\"700\"><br>')\n",
    "\n",
    "# Join all content blocks into a single HTML string\n",
    "html_content = ''.join(content_blocks)\n",
    "\n",
    "# Display the combined content\n",
    "display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Formatted Output\n",
    "I tried everything I could think of to get the images to stream inline with the text but it appears that doing so with Jupyter Notebook cells is very difficult. I finally had to throw in the towel. I did post to the forums to see if anyone had and answer but, apparently, no one did. You can see if someone finally answered here: https://community.openai.com/t/streaming-markdown-text-and-images-from-assistant-using-code-interpreter/823042/9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
