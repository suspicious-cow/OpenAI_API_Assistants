{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9\n",
    "\n",
    "Univeral code that we will use for the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "from openai import OpenAI\n",
    "\n",
    "# libraries needed for streaming output\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "# additional libraries\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class\n",
    "# This assumes you have the OPENAI_API_KEY environment variable set\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Assistants, Threads, and Messages Review\n",
    "Let's create a new assistant, thread, and some messages for us to use later on and to review the code for creating them.\n",
    "\n",
    "### Creating an Assistant\n",
    "First, let's make an Assistant we can use to communicate with our run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an assistant.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    name=\"Son of Run Tester Assistant\",\n",
    "    metadata={\n",
    "        \"holds_threads\": \"True\",\n",
    "        \"likes_threads\": \"True\",\n",
    "        \"holds_messages\": \"True\",\n",
    "        \"likes_messages\": \"True\",\n",
    "    },\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check the properties.\n",
    "print(assistant)\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)\n",
    "print(assistant.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Thread\n",
    "Now, let's create a Thread that can be used to hold our messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread using the OpenAI API and store it in a variable\n",
    "# The metadata specifies a user identifier\n",
    "thread = client.beta.threads.create(\n",
    "    metadata={\n",
    "        \"user\": \"abc123\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Output the result of the thread creation to the console\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Message\n",
    "Finally, let's create a Message that we can go into the Thread for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message in a specific thread using the client's message creation method.\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,  # ID of the thread where the message will be posted\n",
    "    role=\"user\",  # Role of the entity posting the message\n",
    "    content=\"Tell me what a penguin is in 100 words or less.\",  # The textual content of the message\n",
    "    metadata={\"key\": \"value\"}  # Additional data associated with the message in key-value pairs\n",
    ")\n",
    "\n",
    "# Print the entire message object to view its details.\n",
    "print(message)\n",
    "\n",
    "# Print a blank line for better readability of the output.\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print specific attributes of the message.\n",
    "print(message.id)  # The unique identifier of the message\n",
    "print(message.content)  # The content of the message\n",
    "print(message.content[0].text.value)  # Assuming 'content' is a list of text objects, print the value of the first one\n",
    "print(message.role)  # The role associated with the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Streaming Run\n",
    "Let's create a run and get some output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    "# Normally, you would define this class at the top of your script or in a separate file.\n",
    "class EventHandler(AssistantEventHandler):    \n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        \n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(f\"\\n\\noutput >\", flush=True)\n",
    "            for output in delta.code_interpreter.outputs:\n",
    "                if output.type == \"logs\":\n",
    "                    print(f\"\\n{output.logs}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird native to the Southern Hemisphere, particularly Antarctica. Known for their distinctive black and white plumage, penguins have streamlined bodies adapted for swimming and waddle awkwardly on land. They are excellent swimmers, using their flippers to propel through water, where they hunt for fish, krill, and squid. Penguins are social birds, often forming large colonies for breeding and nesting. They endure extreme cold with their dense feathers and a layer of blubber. There are several species of penguins, varying in size and features, such as the Emperor, King, and Adelie penguins."
     ]
    }
   ],
   "source": [
    "# Then, we use the `stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Management\n",
    "We have two options for contolling the amount of tokens used:\n",
    "\n",
    "max_prompt_tokens (integer or null)\n",
    "Optional\n",
    "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete. \n",
    "\n",
    "max_completion_tokens (integer or null)\n",
    "Optional\n",
    "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete. \n",
    "\n",
    "Let's see it in action!\n",
    "\n",
    "First we start with max_prompt_tokens to limit the input tokens that can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg_MAVhSfsYWEP9imHTtk2UrXwT\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird native to the Southern Hemisphere, particularly Antarctica. Known for their distinctive black and white plumage, penguins have streamlined bodies adapted for swimming and waddle awkwardly on land. They are excellent swimmers, using their flippers to propel through water, where they hunt for fish, krill, and squid. Penguins are social birds, often forming large colonies for breeding and nesting. They endure extreme cold with their dense feathers and a layer of blubber. There are several species of penguins, varying in size and features, such as the Emperor, King, and Adelie penguins.'), type='text')]\n",
      "\n",
      "\n",
      "msg_2FiIEQV0NWq74ZBbiaykFV4J\n",
      "[TextContentBlock(text=Text(annotations=[], value='Tell me what a penguin is in 100 words or less.'), type='text')]\n",
      "\n",
      "\n",
      "Total number of messages: 2\n"
     ]
    }
   ],
   "source": [
    "# Let's start by seeing see how many messages we have\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "# Initialize a counter for the messages\n",
    "message_count = 0\n",
    "\n",
    "# Loop through the messages, print the id and content, and count the messages\n",
    "for message in messages:\n",
    "    print(message.id)\n",
    "    print(message.content)\n",
    "    print(\"\\n\")\n",
    "    message_count += 1  # Increment the message count\n",
    "\n",
    "# Print the total number of messages\n",
    "print(f\"Total number of messages: {message_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Run](data=[Run(id='run_P9L2GTrEVUSFa8FbWKOuMv6i', assistant_id='asst_rN1GCMyXuzrXoxdcbu979T67', cancelled_at=None, completed_at=1715816083, created_at=1715816080, expires_at=None, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=1715816080, status='completed', thread_id='thread_OAMXvqWnBHgPMlziOoOiukBO', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=128, prompt_tokens=44, total_tokens=172), temperature=1.0, top_p=1.0, tool_resources={})], object='list', first_id='run_P9L2GTrEVUSFa8FbWKOuMv6i', last_id='run_P9L2GTrEVUSFa8FbWKOuMv6i', has_more=False)\n",
      "\n",
      "\n",
      "\n",
      "run_P9L2GTrEVUSFa8FbWKOuMv6i\n",
      "completed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First let's list our runs to see what we have\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "# Dump all the runs\n",
    "print(runs)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Loop throught the runs and print the id and status\n",
    "for run in runs:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird native to the Southern Hemisphere, particularly Antarctica. Known for their black and white plumage, penguins have streamlined bodies adapted for swimming and waddle awkwardly on land. They are excellent swimmers, using their flippers to propel through water, where they hunt for fish, krill, and squid. Penguins are social birds, often forming large colonies for breeding and nesting. They endure extreme cold with their dense feathers and a layer of blubber. Several species exist, varying in size and features, such as the Emperor, King, and Adelie penguins."
     ]
    }
   ],
   "source": [
    "# Now let's do a run limiting the prompt tokens\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    max_prompt_tokens=5, # must be set to 256 or more\n",
    "    # max_prompt_tokens=256,\n",
    "    event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And list the runs again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_93rVztkwdkaX4EY9CSJWu1FY\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_P9L2GTrEVUSFa8FbWKOuMv6i\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's list our runs to see what we have\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "\n",
    "# Loop throught the runs and print the id and status\n",
    "for run in runs:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now limiting the completion tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird native to the Southern Hemisphere,"
     ]
    }
   ],
   "source": [
    "# Now let's do a run limiting the completion tokens\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    max_completion_tokens=5, # must be set to 16 or more\n",
    "    # max_completion_tokens=16,\n",
    "    event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_SSgZthpLe616QD6e2NvGD9ct\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_completion_tokens')\n",
      "\n",
      "\n",
      "run_93rVztkwdkaX4EY9CSJWu1FY\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_P9L2GTrEVUSFa8FbWKOuMv6i\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's list our runs again\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "\n",
    "# Loop throught the runs and print the id and status\n",
    "for run in runs:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine truncation_strategy:\n",
    "\n",
    "truncation_strategy (object)\n",
    "Optional\n",
    "Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.\n",
    "\n",
    "Properties:\n",
    "type (string)\n",
    "Required\n",
    "The truncation strategy to use for the thread. The default is auto. If set to last_messages, the thread will be truncated to the n most recent messages in the thread. When set to auto, messages in the middle of the thread will be dropped to fit the context length of the model, max_prompt_tokens.\n",
    "\n",
    "last_messages (integer or null)\n",
    "Optional\n",
    "The number of most recent messages from the thread when constructing the context for the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird native to the Southern Hemisphere,"
     ]
    }
   ],
   "source": [
    "# Now let's use a truncation strategy on the last set of messages\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    max_prompt_tokens=1000,\n",
    "    truncation_strategy={  # Adding a truncation strategy to control the context of the conversation\n",
    "        \"type\": \"last_messages\",  # Strategy to keep only the most recent messages\n",
    "        \"last_messages\": 5  # Keep the last 5 messages in the context window\n",
    "    },\n",
    "    event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird native to the Southern Hemisphere,"
     ]
    }
   ],
   "source": [
    "# Now let's use a truncation strategy where the system decides what messages to cut\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    max_prompt_tokens=1000,\n",
    "    truncation_strategy={  # Adding a truncation strategy to control the context of the conversation\n",
    "        \"type\": \"auto\",  # Strategy to keep only prompt\n",
    "    },\n",
    "    event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg_n07urra4ymORoREqVmbyfx2w\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird native to the Southern Hemisphere,'), type='text')]\n",
      "\n",
      "\n",
      "msg_cXDkEDtEa6fEpN7Ra0YNHINT\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird native to the Southern Hemisphere,'), type='text')]\n",
      "\n",
      "\n",
      "msg_LCX8KU39URj9UfpDrADUTuMd\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird native to the Southern Hemisphere,'), type='text')]\n",
      "\n",
      "\n",
      "msg_J5zf4nlPXhcuYQgyCRIJz9rj\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird native to the Southern Hemisphere, particularly Antarctica. Known for their black and white plumage, penguins have streamlined bodies adapted for swimming and waddle awkwardly on land. They are excellent swimmers, using their flippers to propel through water, where they hunt for fish, krill, and squid. Penguins are social birds, often forming large colonies for breeding and nesting. They endure extreme cold with their dense feathers and a layer of blubber. Several species exist, varying in size and features, such as the Emperor, King, and Adelie penguins.'), type='text')]\n",
      "\n",
      "\n",
      "msg_MAVhSfsYWEP9imHTtk2UrXwT\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird native to the Southern Hemisphere, particularly Antarctica. Known for their distinctive black and white plumage, penguins have streamlined bodies adapted for swimming and waddle awkwardly on land. They are excellent swimmers, using their flippers to propel through water, where they hunt for fish, krill, and squid. Penguins are social birds, often forming large colonies for breeding and nesting. They endure extreme cold with their dense feathers and a layer of blubber. There are several species of penguins, varying in size and features, such as the Emperor, King, and Adelie penguins.'), type='text')]\n",
      "\n",
      "\n",
      "msg_2FiIEQV0NWq74ZBbiaykFV4J\n",
      "[TextContentBlock(text=Text(annotations=[], value='Tell me what a penguin is in 100 words or less.'), type='text')]\n",
      "\n",
      "\n",
      "Total number of messages: 6\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many messages we have now\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "# Initialize a counter for the messages\n",
    "message_count = 0\n",
    "\n",
    "# Loop through the messages, print the id and content, and count the messages\n",
    "for message in messages:\n",
    "    print(message.id)\n",
    "    print(message.content)\n",
    "    print(\"\\n\")\n",
    "    message_count += 1  # Increment the message count\n",
    "\n",
    "# Print the total number of messages\n",
    "print(f\"Total number of messages: {message_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Tool Choice and Response Format\n",
    "In addition to all the other arguments we can modify, we also have tool_choice and response_format:\n",
    "\n",
    "tool_choice (string or object)\n",
    "\n",
    "Optional\n",
    "\n",
    "Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {\"type\": \"file_search\"} or {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n",
    "\n",
    "response_format (string or object)\n",
    "\n",
    "Optional\n",
    "\n",
    "Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n",
    "\n",
    "Setting to { \"type\": \"json_object\" } enables JSON mode, which guarantees the message the model generates is valid JSON.\n",
    "\n",
    "Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > {\n",
      "    \"description\": \"A penguin is a flightless seabird native to the Southern Hemisphere, particularly Antarctica. Known for their distinctive black and white plumage, penguins have streamlined bodies adapted for swimming and waddle awkwardly on land. They are excellent swimmers, using their flippers to propel through water, where they hunt for fish, krill, and squid. Penguins are social birds, often forming large colonies for breeding and nesting. They endure extreme cold with their dense feathers and a layer of blubber. There are several species of penguins, varying in size and features, such as the Emperor, King, and Adelie penguins.\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Then, we use the `stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    additional_instructions=\"Make sure your output is in JSON format.\",\n",
    "    response_format={\"type\" : \"json_object\"},\n",
    "    tool_choice=None,\n",
    "    event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Runs\n",
    "thread_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the thread the run belongs to.\n",
    "\n",
    "limit\n",
    "(integer)\n",
    "\n",
    "Optional\n",
    "Defaults to 20\n",
    "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n",
    "\n",
    "order\n",
    "(string)\n",
    "\n",
    "Optional\n",
    "Defaults to desc\n",
    "Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n",
    "\n",
    "after\n",
    "(string)\n",
    "\n",
    "Optional\n",
    "A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n",
    "\n",
    "before\n",
    "(string)\n",
    "\n",
    "Optional\n",
    "A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_BmslqqGIT1S1cfEH5qJ4mKRo\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_8Cq8IebY665PFDU7rDiIzbOI\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_K5H7P1b7QSk5LxQhTNYIvH7w\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_8efzAgLzZBkmA2SVP91dmTwV\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_SSgZthpLe616QD6e2NvGD9ct\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_completion_tokens')\n",
      "\n",
      "\n",
      "run_93rVztkwdkaX4EY9CSJWu1FY\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_P9L2GTrEVUSFa8FbWKOuMv6i\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's list our runs to see what we have\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id,\n",
    "    order=\"desc\",\n",
    ")\n",
    "\n",
    "\n",
    "# Loop throught the runs and print the id and status\n",
    "for run in runs:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Runs\n",
    "\n",
    "thread_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the thread that was run.\n",
    "\n",
    "run_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the run to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run ID: run_BmslqqGIT1S1cfEH5qJ4mKRo\n",
      "run_BmslqqGIT1S1cfEH5qJ4mKRo\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_8Cq8IebY665PFDU7rDiIzbOI\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_K5H7P1b7QSk5LxQhTNYIvH7w\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_8efzAgLzZBkmA2SVP91dmTwV\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_SSgZthpLe616QD6e2NvGD9ct\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_completion_tokens')\n",
      "\n",
      "\n",
      "run_93rVztkwdkaX4EY9CSJWu1FY\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_P9L2GTrEVUSFa8FbWKOuMv6i\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's list our runs to see what we have\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id,\n",
    "    order=\"desc\",\n",
    ")\n",
    "\n",
    "# Convert the normal SyncCursorPage object we get back to an actual list\n",
    "runs_list = list(runs)\n",
    "\n",
    "# Check if there are any runs\n",
    "if runs_list:\n",
    "    # Get the run id of the last run (first in the list since it's sorted in descending order)\n",
    "    last_run_id = runs_list[0].id\n",
    "    print(\"Last run ID:\", last_run_id)\n",
    "\n",
    "# Loop through the runs and print the id and status\n",
    "for run in runs_list:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_BmslqqGIT1S1cfEH5qJ4mKRo', assistant_id='asst_rN1GCMyXuzrXoxdcbu979T67', cancelled_at=None, completed_at=1715816584, created_at=1715816580, expires_at=None, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant. Make sure your output is in JSON format.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format=AssistantResponseFormat(type='json_object'), started_at=1715816580, status='completed', thread_id='thread_OAMXvqWnBHgPMlziOoOiukBO', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=134, prompt_tokens=499, total_tokens=633), temperature=1.0, top_p=1.0, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=runs_list[0].id\n",
    ")\n",
    "\n",
    "print(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thread and Run\n",
    "We have a helper function that can be used to create a thread and run it in one shot.\n",
    "\n",
    "assistant_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "\n",
    "The ID of the assistant to use to execute this run.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_xCY590BpQ4xHMD3KYEyOZpTS', assistant_id='asst_rN1GCMyXuzrXoxdcbu979T67', cancelled_at=None, completed_at=None, created_at=1715841824, expires_at=1715842424, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_tODiMx7R3IUJ8dQJVCx1lzGy', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
      "\n",
      "\n",
      "thread_tODiMx7R3IUJ8dQJVCx1lzGy\n",
      "\n",
      "\n",
      "[TextContentBlock(text=Text(annotations=[], value=\"Explain deep learning to me like I'm a 5 year old.\"), type='text')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run = client.beta.threads.create_and_run(\n",
    "    assistant_id=assistant.id,\n",
    "    thread={\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Explain deep learning to me like I'm a 5 year old.\"}\n",
    "    ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(run)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(run.thread_id)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the messages from the thread\n",
    "messages = client.beta.threads.messages.list(thread_id=run.thread_id)\n",
    "\n",
    "# Loop through the messages and print the content\n",
    "for message in messages:\n",
    "    print(message.content)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
