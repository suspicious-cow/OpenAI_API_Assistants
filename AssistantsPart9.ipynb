{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9\n",
    "\n",
    "Universal code that we will use for the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler # Used for handling events related to OpenAI assistants\n",
    "\n",
    "# Additional libraries for time and date manipulation\n",
    "import time\n",
    "import pytz\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Assistants, Threads, and Messages Review\n",
    "Let's create a new assistant, thread, and some messages for us to use later on and to review the code for creating them.\n",
    "\n",
    "### Creating an Assistant\n",
    "First, let's make an Assistant we can use to communicate with our run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_GQAyOA9rDwc6hLpxzIbTH9fm', created_at=1715845576, description=None, instructions='You are a helpful assistant.', metadata={'holds_threads': 'True', 'likes_threads': 'True', 'holds_messages': 'True', 'likes_messages': 'True'}, model='gpt-4o', name='Son of Run Tester Assistant', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Son of Run Tester Assistant\n",
      "{'holds_threads': 'True', 'likes_threads': 'True', 'holds_messages': 'True', 'likes_messages': 'True'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    instructions=\"You are a helpful assistant.\",  # Set the instructions for the assistant.\n",
    "    name=\"Son of Run Tester Assistant\",  # Give the assistant a name.\n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"holds_threads\": \"True\",\n",
    "        \"likes_threads\": \"True\",\n",
    "        \"holds_messages\": \"True\",\n",
    "        \"likes_messages\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Thread\n",
    "Now, let's create a Thread that can be used to hold our messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_DuiqEcj75jTFpNALdGumxQnb', created_at=1715845598, metadata={'user': 'abc123'}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# Create a thread using the OpenAI API and store it in a variable.\n",
    "# The metadata specifies a user identifier.\n",
    "thread = client.beta.threads.create(\n",
    "    metadata={\n",
    "        \"user\": \"abc123\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Output the result of the thread creation to the console.\n",
    "print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Message\n",
    "Finally, let's create a Message that we can go into the Thread for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(id='msg_sSyqoMb4eYREEN4cEEFdoLom', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Tell me what a penguin is in 100 words or less.'), type='text')], created_at=1715845607, incomplete_at=None, incomplete_details=None, metadata={'key': 'value'}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_DuiqEcj75jTFpNALdGumxQnb')\n",
      "\n",
      "\n",
      "msg_sSyqoMb4eYREEN4cEEFdoLom\n",
      "[TextContentBlock(text=Text(annotations=[], value='Tell me what a penguin is in 100 words or less.'), type='text')]\n",
      "Tell me what a penguin is in 100 words or less.\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "# Create a message in a specific thread using the client's message creation method.\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,  # ID of the thread where the message will be posted\n",
    "    role=\"user\",  # Role of the entity posting the message\n",
    "    content=\"Tell me what a penguin is in 100 words or less.\",  # The textual content of the message\n",
    "    metadata={\"key\": \"value\"}  # Additional data associated with the message in key-value pairs\n",
    ")\n",
    "\n",
    "# Print the entire message object to view its details.\n",
    "print(message)\n",
    "\n",
    "# Print a blank line for better readability of the output.\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print specific attributes of the message.\n",
    "print(message.id)  # The unique identifier of the message\n",
    "print(message.content)  # The content of the message\n",
    "print(message.content[0].text.value)  # Assuming 'content' is a list of text objects, print the value of the first one\n",
    "print(message.role)  # The role associated with the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Streaming Run\n",
    "Let's create a run and get some output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EventHandler class to define how we want to handle the events in the response stream.\n",
    "# Normally, you would define this class at the top of your script or in a separate file.\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\n",
    "        \n",
    "        This method is called when a complete piece of text is generated by the assistant.\n",
    "        \"\"\"\n",
    "        # Print a prompt indicating the start of assistant's text response.\n",
    "        # 'flush=True' ensures that the output is immediately written to the console.\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\n",
    "        \n",
    "        This method is called for incremental text updates, useful for streaming responses.\n",
    "        \"\"\"\n",
    "        # Print the incremental text as it is being generated.\n",
    "        # 'end=\"\"' prevents adding a new line after each delta.\n",
    "        # 'flush=True' ensures that the output is immediately written to the console.\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\n",
    "        \n",
    "        This method is called when the assistant makes a call to an external tool.\n",
    "        \"\"\"\n",
    "        # Print a prompt indicating the assistant is using a tool.\n",
    "        # 'flush=True' ensures that the output is immediately written to the console.\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\n",
    "        \n",
    "        This method is called for incremental updates during the tool call's execution.\n",
    "        \"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            # If there is an input for the code interpreter, print it.\n",
    "            # 'flush=True' ensures that the output is immediately written to the console.\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "            # If there are outputs from the code interpreter, print them.\n",
    "            if delta.code_interpreter.outputs:\n",
    "                # 'flush=True' ensures that the output is immediately written to the console.\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "            # Loop through each output and print the logs if present.\n",
    "            for output in delta.code_interpreter.outputs:\n",
    "                if output.type == \"logs\":\n",
    "                    # 'flush=True' ensures that the output is immediately written to the console.\n",
    "                    print(f\"\\n{output.logs}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird belonging to the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Known for their distinctive black and white plumage, penguins are adept swimmers, using their flipper-like wings to navigate underwater. They feed mainly on fish, squid, and krill. Penguins are highly social animals, often living in large colonies. They have various species, including the Emperor, King, and Adélie penguins. Adaptations like thick blubber and dense feathers help them survive harsh, cold environments. Penguins also exhibit unique behaviors, such as huddling for warmth and prolonged parental care."
     ]
    }
   ],
   "source": [
    "# Use the `stream` SDK helper with the `EventHandler` class to create the Run\n",
    "# and stream the response.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,         # ID of the thread to run.\n",
    "    assistant_id=assistant.id,   # ID of the assistant to use.\n",
    "    event_handler=EventHandler(),  # Custom event handler for processing events.\n",
    ") as stream:\n",
    "    # Process the stream until it is complete.\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Management\n",
    "We have two options for contolling the amount of tokens used:\n",
    "\n",
    "max_prompt_tokens (integer or null)\n",
    "Optional\n",
    "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete. \n",
    "\n",
    "max_completion_tokens (integer or null)\n",
    "Optional\n",
    "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete. \n",
    "\n",
    "Let's see it in action!\n",
    "\n",
    "First we start with max_prompt_tokens to limit the input tokens that can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg_s9MACZG7h6NsLyOdf6g6B3MT\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird belonging to the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Known for their distinctive black and white plumage, penguins are adept swimmers, using their flipper-like wings to navigate underwater. They feed mainly on fish, squid, and krill. Penguins are highly social animals, often living in large colonies. They have various species, including the Emperor, King, and Adélie penguins. Adaptations like thick blubber and dense feathers help them survive harsh, cold environments. Penguins also exhibit unique behaviors, such as huddling for warmth and prolonged parental care.'), type='text')]\n",
      "\n",
      "\n",
      "msg_sSyqoMb4eYREEN4cEEFdoLom\n",
      "[TextContentBlock(text=Text(annotations=[], value='Tell me what a penguin is in 100 words or less.'), type='text')]\n",
      "\n",
      "\n",
      "Total number of messages: 2\n"
     ]
    }
   ],
   "source": [
    "# Let's start by seeing how many messages we have.\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id  # ID of the thread to list messages from.\n",
    ")\n",
    "\n",
    "# Initialize a counter for the messages.\n",
    "message_count = 0\n",
    "\n",
    "# Loop through the messages, print the id and content, and count the messages.\n",
    "for message in messages:\n",
    "    print(message.id)      # Print the ID of the message.\n",
    "    print(message.content)  # Print the content of the message.\n",
    "    print(\"\\n\")             # Print a newline for readability.\n",
    "    message_count += 1      # Increment the message count.\n",
    "\n",
    "# Print the total number of messages.\n",
    "print(f\"Total number of messages: {message_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Run](data=[Run(id='run_ydOBWX453Qpf3ztSzho642fm', assistant_id='asst_GQAyOA9rDwc6hLpxzIbTH9fm', cancelled_at=None, completed_at=1715845805, created_at=1715845802, expires_at=None, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=1715845802, status='completed', thread_id='thread_DuiqEcj75jTFpNALdGumxQnb', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=133, prompt_tokens=44, total_tokens=177), temperature=1.0, top_p=1.0, tool_resources={})], object='list', first_id='run_ydOBWX453Qpf3ztSzho642fm', last_id='run_ydOBWX453Qpf3ztSzho642fm', has_more=False)\n",
      "\n",
      "\n",
      "\n",
      "run_ydOBWX453Qpf3ztSzho642fm\n",
      "completed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's list our runs to see what we have.\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id  # ID of the thread to list runs from.\n",
    ")\n",
    "\n",
    "# Dump all the runs.\n",
    "print(runs)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Loop through the runs and print the id and status.\n",
    "for run in runs:\n",
    "    print(run.id)      # Print the ID of the run.\n",
    "    print(run.status)  # Print the status of the run.\n",
    "    print(\"\\n\")        # Print a newline for readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do a run limiting the prompt tokens.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,          # ID of the thread to run.\n",
    "    assistant_id=assistant.id,    # ID of the assistant to use.\n",
    "    # max_prompt_tokens=5,        # Limit the maximum number of prompt tokens to get an error\n",
    "    max_prompt_tokens=256,        # Limit the maximum number of prompt tokens.\n",
    "    event_handler=EventHandler(), # Custom event handler for processing events.\n",
    ") as stream:\n",
    "    # Process the stream until it is complete.\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Run](data=[Run(id='run_JoaOm2eQGZMXzuqSS8Ghjsde', assistant_id='asst_GQAyOA9rDwc6hLpxzIbTH9fm', cancelled_at=None, completed_at=1715845963, created_at=1715845960, expires_at=None, failed_at=None, incomplete_details=IncompleteDetails(reason='max_prompt_tokens'), instructions='You are a helpful assistant.', last_error=None, max_completion_tokens=None, max_prompt_tokens=256, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=1715845960, status='incomplete', thread_id='thread_DuiqEcj75jTFpNALdGumxQnb', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=122, prompt_tokens=179, total_tokens=301), temperature=1.0, top_p=1.0, tool_resources={}), Run(id='run_ydOBWX453Qpf3ztSzho642fm', assistant_id='asst_GQAyOA9rDwc6hLpxzIbTH9fm', cancelled_at=None, completed_at=1715845805, created_at=1715845802, expires_at=None, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=1715845802, status='completed', thread_id='thread_DuiqEcj75jTFpNALdGumxQnb', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=133, prompt_tokens=44, total_tokens=177), temperature=1.0, top_p=1.0, tool_resources={})], object='list', first_id='run_JoaOm2eQGZMXzuqSS8Ghjsde', last_id='run_ydOBWX453Qpf3ztSzho642fm', has_more=False)\n",
      "\n",
      "\n",
      "\n",
      "run_JoaOm2eQGZMXzuqSS8Ghjsde\n",
      "incomplete\n",
      "\n",
      "\n",
      "run_ydOBWX453Qpf3ztSzho642fm\n",
      "completed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's list our runs again to see what we have.\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id  # ID of the thread to list runs from.\n",
    ")\n",
    "\n",
    "# Dump all the runs.\n",
    "print(runs)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Loop through the runs and print the id and status.\n",
    "for run in runs:\n",
    "    print(run.id)      # Print the ID of the run.\n",
    "    print(run.status)  # Print the status of the run.\n",
    "    print(\"\\n\")        # Print a newline for readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now limiting the completion tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird from the Spheniscidae"
     ]
    }
   ],
   "source": [
    "# Now let's do a run limiting the completion tokens.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,         # ID of the thread to run.\n",
    "    assistant_id=assistant.id,   # ID of the assistant to use.\n",
    "    # max_completion_tokens=16,    # Limit the maximum number of completion tokens to get an error\n",
    "    max_completion_tokens=16,    # Limit the maximum number of completion tokens.\n",
    "    event_handler=EventHandler(),  # Custom event handler for processing events.\n",
    ") as stream:\n",
    "    # Process the stream until it is complete.\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_M7Y3X5dseTOuhgW5N8yhcavk\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_completion_tokens')\n",
      "\n",
      "\n",
      "run_JoaOm2eQGZMXzuqSS8Ghjsde\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_ydOBWX453Qpf3ztSzho642fm\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's list our runs again\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "\n",
    "# Loop throught the runs and print the id and status\n",
    "for run in runs:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncation Strategy\n",
    "We will need to manage having a lot of context being sent via messages and managing the tokens sent each time.\n",
    "\n",
    "\n",
    "truncation_strategy (object)\n",
    "Optional\n",
    "Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.\n",
    "\n",
    "Properties:\n",
    "type (string)\n",
    "Required\n",
    "The truncation strategy to use for the thread. The default is auto. If set to last_messages, the thread will be truncated to the n most recent messages in the thread. When set to auto, messages in the middle of the thread will be dropped to fit the context length of the model, max_prompt_tokens.\n",
    "\n",
    "last_messages (integer or null)\n",
    "Optional\n",
    "The number of most recent messages from the thread when constructing the context for the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird from the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Recognizable by their black and white plumage, penguins are excellent swimmers, using their flipper-like wings underwater. They primarily consume fish, squid, and krill. Social in nature, penguins often gather in large colonies. There are various species, including the Emperor, King, and Adélie penguins. They possess adaptations like thick blubber and dense feathers to endure cold environments. Notable behaviors include huddling for warmth and extended parental care."
     ]
    }
   ],
   "source": [
    "# Now let's use a truncation strategy on the last set of messages.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,           # ID of the thread to run.\n",
    "    assistant_id=assistant.id,     # ID of the assistant to use.\n",
    "    max_prompt_tokens=1000,        # Limit the maximum number of prompt tokens.\n",
    "    truncation_strategy={          # Adding a truncation strategy to control the context of the conversation.\n",
    "        \"type\": \"last_messages\",   # Strategy to keep only the most recent messages.\n",
    "        \"last_messages\": 5         # Keep the last 5 messages in the context window.\n",
    "    },\n",
    "    event_handler=EventHandler(),  # Custom event handler for processing events.\n",
    ") as stream:\n",
    "    # Process the stream until it is complete.\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > A penguin is a flightless seabird from the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Recognizable by their black and white plumage, penguins are excellent swimmers, using their flipper-like wings underwater. They primarily consume fish, squid, and krill. Social in nature, penguins often gather in large colonies. There are various species, including the Emperor, King, and Adélie penguins. They possess adaptations like thick blubber and dense feathers to endure cold environments. Unique behaviors include huddling for warmth and extended parental care."
     ]
    }
   ],
   "source": [
    "# Now let's use a truncation strategy where the system decides what messages to cut.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,           # ID of the thread to run.\n",
    "    assistant_id=assistant.id,     # ID of the assistant to use.\n",
    "    max_prompt_tokens=1000,        # Limit the maximum number of prompt tokens.\n",
    "    truncation_strategy={          # Adding a truncation strategy to control the context of the conversation.\n",
    "        \"type\": \"auto\"             # Strategy where the system automatically decides which messages to keep.\n",
    "    },\n",
    "    event_handler=EventHandler(),  # Custom event handler for processing events.\n",
    ") as stream:\n",
    "    # Process the stream until it is complete.\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg_MhiAECGm10oHLcXv6SssXX2a\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird from the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Recognizable by their black and white plumage, penguins are excellent swimmers, using their flipper-like wings underwater. They primarily consume fish, squid, and krill. Social in nature, penguins often gather in large colonies. There are various species, including the Emperor, King, and Adélie penguins. They possess adaptations like thick blubber and dense feathers to endure cold environments. Unique behaviors include huddling for warmth and extended parental care.'), type='text')]\n",
      "\n",
      "\n",
      "msg_1x42n9UjyvEtayM9kPXckoe7\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird from the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Recognizable by their black and white plumage, penguins are excellent swimmers, using their flipper-like wings underwater. They primarily consume fish, squid, and krill. Social in nature, penguins often gather in large colonies. There are various species, including the Emperor, King, and Adélie penguins. They possess adaptations like thick blubber and dense feathers to endure cold environments. Notable behaviors include huddling for warmth and extended parental care.'), type='text')]\n",
      "\n",
      "\n",
      "msg_MfiEGIZYNFCP4oUdNqfFQZ9L\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird from the Spheniscidae'), type='text')]\n",
      "\n",
      "\n",
      "msg_COYDFkNowy1peApDNRl6n615\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird from the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Recognizable by their black and white plumage, penguins are excellent swimmers, using their flipper-like wings underwater. They primarily consume fish, squid, and krill. Social in nature, penguins often gather in large colonies. There are various species, including the Emperor, King, and Adélie penguins. They possess adaptations like thick blubber and dense feathers to endure cold environments. Unique behaviors include huddling for warmth and extended parental care.'), type='text')]\n",
      "\n",
      "\n",
      "msg_s9MACZG7h6NsLyOdf6g6B3MT\n",
      "[TextContentBlock(text=Text(annotations=[], value='A penguin is a flightless seabird belonging to the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Known for their distinctive black and white plumage, penguins are adept swimmers, using their flipper-like wings to navigate underwater. They feed mainly on fish, squid, and krill. Penguins are highly social animals, often living in large colonies. They have various species, including the Emperor, King, and Adélie penguins. Adaptations like thick blubber and dense feathers help them survive harsh, cold environments. Penguins also exhibit unique behaviors, such as huddling for warmth and prolonged parental care.'), type='text')]\n",
      "\n",
      "\n",
      "msg_sSyqoMb4eYREEN4cEEFdoLom\n",
      "[TextContentBlock(text=Text(annotations=[], value='Tell me what a penguin is in 100 words or less.'), type='text')]\n",
      "\n",
      "\n",
      "Total number of messages: 6\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many messages we have now\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "# Initialize a counter for the messages\n",
    "message_count = 0\n",
    "\n",
    "# Loop through the messages, print the id and content, and count the messages\n",
    "for message in messages:\n",
    "    print(message.id)\n",
    "    print(message.content)\n",
    "    print(\"\\n\")\n",
    "    message_count += 1  # Increment the message count\n",
    "\n",
    "# Print the total number of messages\n",
    "print(f\"Total number of messages: {message_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Tool Choice and Response Format\n",
    "In addition to all the other arguments we can modify, we also have tool_choice and response_format:\n",
    "\n",
    "tool_choice (string or object)\n",
    "\n",
    "Optional\n",
    "\n",
    "Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user. Specifying a particular tool like {\"type\": \"file_search\"} or {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool.\n",
    "\n",
    "response_format (string or object)\n",
    "\n",
    "Optional\n",
    "\n",
    "Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since gpt-3.5-turbo-1106.\n",
    "\n",
    "Setting to { \"type\": \"json_object\" } enables JSON mode, which guarantees the message the model generates is valid JSON.\n",
    "\n",
    "Important: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant text > {\n",
      "  \"description\": \"A penguin is a flightless seabird from the Spheniscidae family, primarily found in the Southern Hemisphere, especially Antarctica. Recognizable by their black and white plumage, penguins are excellent swimmers, using their flipper-like wings underwater. They primarily consume fish, squid, and krill. Social in nature, penguins often gather in large colonies. There are various species, including the Emperor, King, and Adélie penguins. They possess adaptations like thick blubber and dense feathers to endure cold environments. Unique behaviors include huddling for warmth and extended parental care.\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Use the `stream` SDK helper with the `EventHandler` class to create the Run\n",
    "# and stream the response.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,  # ID of the thread to run.\n",
    "    assistant_id=assistant.id,  # ID of the assistant to use.\n",
    "    additional_instructions=\"Make sure your output is in JSON format.\",  # Instructions for JSON output.\n",
    "    response_format={\"type\": \"json_object\"},  # Specify response format as JSON object.\n",
    "    tool_choice=None,\n",
    "    event_handler=EventHandler(),  # Custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Process the stream until complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Runs\n",
    "thread_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the thread the run belongs to.\n",
    "\n",
    "limit\n",
    "(integer)\n",
    "\n",
    "Optional\n",
    "Defaults to 20\n",
    "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n",
    "\n",
    "order\n",
    "(string)\n",
    "\n",
    "Optional\n",
    "Defaults to desc\n",
    "Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n",
    "\n",
    "after\n",
    "(string)\n",
    "\n",
    "Optional\n",
    "A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n",
    "\n",
    "before\n",
    "(string)\n",
    "\n",
    "Optional\n",
    "A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_wfdnEzSVPZ90Q7JKAhpK1SPg\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_2naxlt3UFgtdfVkf7jnHzWId\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_dsKOymAtfCKdYU7r9c2mqnH9\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_OfASG2aCcpcFspNMMp6muGL1\n",
      "failed\n",
      "None\n",
      "\n",
      "\n",
      "run_M7Y3X5dseTOuhgW5N8yhcavk\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_completion_tokens')\n",
      "\n",
      "\n",
      "run_JoaOm2eQGZMXzuqSS8Ghjsde\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_ydOBWX453Qpf3ztSzho642fm\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List our runs to see what we have\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id,\n",
    "    order=\"desc\",  # Order runs in descending order\n",
    ")\n",
    "\n",
    "# Loop through the runs and print the id, status, and incomplete details\n",
    "for run in runs:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Runs\n",
    "\n",
    "thread_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the thread that was run.\n",
    "\n",
    "run_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the run to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run ID: run_wfdnEzSVPZ90Q7JKAhpK1SPg\n",
      "run_wfdnEzSVPZ90Q7JKAhpK1SPg\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_2naxlt3UFgtdfVkf7jnHzWId\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_dsKOymAtfCKdYU7r9c2mqnH9\n",
      "completed\n",
      "None\n",
      "\n",
      "\n",
      "run_OfASG2aCcpcFspNMMp6muGL1\n",
      "failed\n",
      "None\n",
      "\n",
      "\n",
      "run_M7Y3X5dseTOuhgW5N8yhcavk\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_completion_tokens')\n",
      "\n",
      "\n",
      "run_JoaOm2eQGZMXzuqSS8Ghjsde\n",
      "incomplete\n",
      "IncompleteDetails(reason='max_prompt_tokens')\n",
      "\n",
      "\n",
      "run_ydOBWX453Qpf3ztSzho642fm\n",
      "completed\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List our runs to see what we have\n",
    "runs = client.beta.threads.runs.list(\n",
    "    thread_id=thread.id,\n",
    "    order=\"desc\",  # Order runs in descending order\n",
    ")\n",
    "\n",
    "# Convert the normal SyncCursorPage object we get back to an actual list\n",
    "runs_list = list(runs)\n",
    "\n",
    "# Check if there are any runs\n",
    "if runs_list:\n",
    "    # Get the run id of the last run (first in the list since it's sorted in descending order)\n",
    "    last_run_id = runs_list[0].id\n",
    "    print(\"Last run ID:\", last_run_id)\n",
    "\n",
    "# Loop through the runs and print the id, status, and incomplete details\n",
    "for run in runs_list:\n",
    "    print(run.id)\n",
    "    print(run.status)\n",
    "    print(run.incomplete_details)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_wfdnEzSVPZ90Q7JKAhpK1SPg', assistant_id='asst_GQAyOA9rDwc6hLpxzIbTH9fm', cancelled_at=None, completed_at=1715846478, created_at=1715846475, expires_at=None, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant. Make sure your output is in JSON format.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format=AssistantResponseFormat(type='json_object'), started_at=1715846475, status='completed', thread_id='thread_DuiqEcj75jTFpNALdGumxQnb', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=128, prompt_tokens=584, total_tokens=712), temperature=1.0, top_p=1.0, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the details of a specific run\n",
    "run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=runs_list[0].id  # Use the ID of the first run in the list that was sorted descending and therefore is the last run to happen\n",
    ")\n",
    "\n",
    "# Print the details of the retrieved run\n",
    "print(run)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thread and Run\n",
    "We have a helper function that can be used to create a thread and run it in one shot.\n",
    "\n",
    "assistant_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "\n",
    "The ID of the assistant to use to execute this run.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_p9bOoTvOs5fEEOjBMBpD02oF', assistant_id='asst_GQAyOA9rDwc6hLpxzIbTH9fm', cancelled_at=None, completed_at=None, created_at=1715846869, expires_at=1715847469, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_oRArZDdlArpjwpOe0mjPZS5S', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n",
      "\n",
      "\n",
      "thread_oRArZDdlArpjwpOe0mjPZS5S\n",
      "\n",
      "\n",
      "run_p9bOoTvOs5fEEOjBMBpD02oF\n",
      "completed\n",
      "\n",
      "\n",
      "[TextContentBlock(text=Text(annotations=[], value=\"Explain deep learning to me like I'm a 5 year old. In 50 words or less.\"), type='text')]\n",
      "\n",
      "\n",
      "[TextContentBlock(text=Text(annotations=[], value='Deep learning is like teaching a computer to be smart by showing it lots of pictures or sounds. It learns to recognize things, like how you learn by looking at lots of animal pictures to know what a dog or cat looks like.'), type='text')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and run a thread with a specific message\n",
    "run = client.beta.threads.create_and_run(\n",
    "    assistant_id=assistant.id,  # ID of the assistant to use.\n",
    "    thread={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"Explain deep learning to me like I'm a 5 year old. In 50 words or less.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the run details\n",
    "print(run)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the thread ID of the run\n",
    "print(run.thread_id)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Sleep for a few seconds to allow the run to complete\n",
    "time.sleep(10)\n",
    "\n",
    "# Retrieve the latest status of the run\n",
    "run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=run.thread_id,  # Use the thread ID from the created run.\n",
    "    run_id=run.id  # Use the run ID from the created run.\n",
    ")\n",
    "\n",
    "# Print the run ID and status\n",
    "print(run.id)\n",
    "print(run.status)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the messages from the thread, ordered in ascending order\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=run.thread_id,  # Use the thread ID from the run.\n",
    "    order=\"asc\"  # Order messages in ascending order\n",
    ")\n",
    "\n",
    "# Loop through the messages and print the content\n",
    "for message in messages:\n",
    "    print(message.content)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Runs\n",
    "You can only modify the metadata on runs at this time.\n",
    "\n",
    "thread_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the thread that was run.\n",
    "\n",
    "run_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the run to modify.\n",
    "\n",
    "Request body\n",
    "(metadata)\n",
    "map\n",
    "\n",
    "Optional\n",
    "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_p9bOoTvOs5fEEOjBMBpD02oF\n",
      "{}\n",
      "\n",
      "\n",
      "run_p9bOoTvOs5fEEOjBMBpD02oF\n",
      "{'user_id': 'user_abc123'}\n"
     ]
    }
   ],
   "source": [
    "# Show our run information before modification\n",
    "print(run.id)  # Print the run ID\n",
    "print(run.metadata)  # Print the metadata of the run\n",
    "print(\"\\n\")\n",
    "\n",
    "# Update the run's metadata\n",
    "run = client.beta.threads.runs.update(\n",
    "    thread_id=run.thread_id,  # Use the thread ID from the run\n",
    "    run_id=run.id,  # Use the run ID\n",
    "    metadata={\"user_id\": \"user_abc123\"},  # New metadata to update\n",
    ")\n",
    "\n",
    "# Show our run information after modification\n",
    "print(run.id)  # Print the run ID\n",
    "print(run.metadata)  # Print the updated metadata of the run\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canceling Runs\n",
    "You can cancel any run that has a state of in_progress at any time. \n",
    "\n",
    "thread_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the thread to which this run belongs.\n",
    "\n",
    "run_id\n",
    "(string)\n",
    "\n",
    "Required\n",
    "The ID of the run to cancel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_yeSCEVIyhFLYSBrAbBThbY7l\n",
      "queued\n",
      "---------------\n",
      "\n",
      "run_yeSCEVIyhFLYSBrAbBThbY7l\n",
      "queued\n",
      "---------------\n",
      "\n",
      "run_yeSCEVIyhFLYSBrAbBThbY7l\n",
      "in_progress\n",
      "Cancelling the run.\n",
      "---------------\n",
      "\n",
      "run_yeSCEVIyhFLYSBrAbBThbY7l\n",
      "cancelling\n",
      "---------------\n",
      "\n",
      "run_yeSCEVIyhFLYSBrAbBThbY7l\n",
      "cancelled\n",
      "---------------\n",
      "\n",
      "=============== Cancelled Run Information ================\n",
      "\n",
      "run_yeSCEVIyhFLYSBrAbBThbY7l\n",
      "cancelled\n",
      "1715846952\n",
      "2024-05-16 03:09:11 CDT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Create a new run with the stream option set to True\n",
    "stream_run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,  # ID of the thread to run.\n",
    "    assistant_id=assistant.id,  # ID of the assistant to use.\n",
    "    stream=True  # Enable streaming for the run.\n",
    ")\n",
    "\n",
    "# Variable to hold the cancelled run object\n",
    "cancelled_run = None\n",
    "\n",
    "# Continue processing the new run\n",
    "for event in stream_run:\n",
    "    # Check if 'status' is an attribute of the event data\n",
    "    if hasattr(event.data, 'status'):\n",
    "        print(event.data.id)  # Print the event ID\n",
    "        print(event.data.status)  # Print the event status\n",
    "\n",
    "        # Cancel the run if it is in progress\n",
    "        if event.data.status == \"in_progress\":\n",
    "            print(\"Cancelling the run.\")\n",
    "            cancelled_run = client.beta.threads.runs.cancel(\n",
    "                thread_id=thread.id,  # ID of the thread\n",
    "                run_id=event.data.id  # ID of the run to cancel\n",
    "            )\n",
    "    else:\n",
    "        print(f\"Event ID: {event.data.id} does not have a status attribute.\")\n",
    "        print(event.data.delta)  # Print the delta of the event data if no status attribute\n",
    "    print(\"---------------\\n\")\n",
    "\n",
    "# Retrieve the latest status of the cancelled run\n",
    "cancelled_run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,  # ID of the thread\n",
    "    run_id=cancelled_run.id  # ID of the cancelled run\n",
    ")\n",
    "\n",
    "# Show the run ID and when it was cancelled\n",
    "print(\"=============== Cancelled Run Information ================\\n\")\n",
    "print(cancelled_run.id)  # Print the run ID\n",
    "print(cancelled_run.status)  # Print the status of the cancelled run\n",
    "print(cancelled_run.cancelled_at)  # Print the cancellation timestamp\n",
    "\n",
    "# Convert the created date/time in Unix format directly to Central Time and format it\n",
    "formatted_date = datetime.datetime.fromtimestamp(cancelled_run.created_at, tz=pytz.utc) \\\n",
    "    .astimezone(pytz.timezone('America/Chicago')) \\\n",
    "    .strftime('%Y-%m-%d %I:%M:%S %Z')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(formatted_date)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
