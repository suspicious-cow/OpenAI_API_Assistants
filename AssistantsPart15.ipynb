{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time  # Used for time-related functions\n",
    "import threading  # Used for creating and managing threads\n",
    "\n",
    "# Third-party library imports\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from IPython.display import display, Markdown, clear_output  # Used for displaying content in Jupyter Notebooks\n",
    "\n",
    "import base64  # Used for encoding and decoding binary data\n",
    "import requests  # Used for making HTTP requests\n",
    "import markdown2  # Used for converting Markdown to HTML\n",
    "from IPython.display import display, HTML  # Used for displaying HTML content in Jupyter Notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our custom event handler class that inherits from AssistantEventHandler for streaming assistant output.\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\"\"\"\n",
    "        # Print the created text to the console\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        # Append the created text to the results list\n",
    "        self.results.append(text)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Print the delta value (partial text) to the console\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        # Append the delta value to the results list\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\"\"\"\n",
    "        # Print the type of the tool call to the console\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            # Check if there is an input in the code interpreter delta\n",
    "            if delta.code_interpreter.input:\n",
    "                # Print the input to the console\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "                # Append the input to the results list\n",
    "                self.results.append(delta.code_interpreter.input)\n",
    "            # Check if there are outputs in the code interpreter delta\n",
    "            if delta.code_interpreter.outputs:\n",
    "                # Print a label for outputs to the console\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "                # Iterate over each output and handle logs specifically\n",
    "                for output in delta.code_interpreter.outputs or []:\n",
    "                    if output.type == \"logs\":\n",
    "                        # Print the logs to the console\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                        # Append the logs to the results list\n",
    "                        self.results.append(output.logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",  # Instructions for the assistant.\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}],  # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    \n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose.\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),  # Open the file in binary read mode.\n",
    "    purpose='assistants'  # Specify the purpose of the file upload.\n",
    ")\n",
    "\n",
    "# Print the details of the uploaded file to check its properties.\n",
    "print(assistant_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the assistant to add tools and tool resources.\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,  # Use the assistant's ID.\n",
    "    tools=[{\"type\": \"code_interpreter\"}],  # Add the code interpreter capability to the assistant.\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]  # Link the uploaded file to the code interpreter tool.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the details of the updated assistant to check its properties.\n",
    "print(assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new assistant thread with an initial user message.\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Stream the assistant's response to the thread.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Use the thread's ID.\n",
    "    assistant_id=assistant.id,  # Use the assistant's ID.\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",  # Provide instructions to the assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Output\n",
    "What if we want to format the markdown output? There are two ways to do it. The \"easy\" way is to just let the output render without streaming and format it afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new assistant thread with an initial user message.\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create and poll a new run for the assistant thread to get the response.\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id  # Specify the assistant ID.\n",
    ")\n",
    "\n",
    "# Retrieve all messages from the thread using the run ID.\n",
    "messages = list(client.beta.threads.messages.list(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    run_id=run.id  # Specify the run ID.\n",
    "))\n",
    "\n",
    "# Extract the content from the first message in the retrieved messages.\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations  # Extract annotations from the message content.\n",
    "citations = []  # Initialize an empty list to store citations.\n",
    "\n",
    "# Process each annotation to replace the text with indexed references and gather citations.\n",
    "for index, annotation in enumerate(annotations):\n",
    "    # Replace the annotated text with an indexed reference in the message content.\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    # Check if there is a file citation in the annotation.\n",
    "    file_citation = getattr(annotation, \"file_citation\", None)\n",
    "    if file_citation:\n",
    "        # Retrieve the cited file's details using its file ID.\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        # Append the citation with the indexed reference and file name to the citations list.\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "# Display the processed message content with indexed references using Markdown.\n",
    "display(Markdown(message_content.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hard\"  (but more user-friendly) way is to stream the output and update the display while streaming to show the formatted text. This is what ChatGPT does when you use it. This will require modifying our event handler to be more streamlined, formatting output, and updating our display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        self.results.append(delta.value)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "# Create a new assistant thread with an initial user message.\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv. With at least one small table of data. Make the information well formatted and easy to read.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Stream the assistant's response to the thread.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",  # Provide instructions to the assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose.\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),  # Open the file in binary read mode.\n",
    "    purpose='assistants'  # Specify the purpose of the file upload.\n",
    ")\n",
    "\n",
    "# Print the details of the uploaded file to check its properties.\n",
    "print(thread_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new thread with an initial user message requesting a summary of the file.\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the daily-bike-share.csv file.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the details of the created thread to check its properties.\n",
    "print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the existing thread to add tool resources, specifically linking the uploaded file.\n",
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,  # Use the ID of the existing thread.\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]  # Link the uploaded file to the code interpreter tool.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the details of the updated thread to check its properties.\n",
    "print(updated_thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it against a new assistant and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the client library.\n",
    "thread_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",  # Instructions for the assistant.\n",
    "    \n",
    "    name=\"Code Interpreter Assistant Using Thread Data\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}],  # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(thread_assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(thread_assistant.name)  # Print the name of the assistant.\n",
    "print(thread_assistant.metadata)  # Print the metadata of the assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the output from the assistant.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=updated_thread.id,  # Use the ID of the updated thread.\n",
    "    assistant_id=thread_assistant.id,  # Use the ID of the newly created assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler to process events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Results from files in Assistants and Threads\n",
    "\n",
    "Let's see what happens if we use an assistant with a file and a thread with a file together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new thread with an initial user message requesting a summary of two files.\n",
    "super_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Give me a summary of the penguins-size.csv and daily-bike-share.csv files. \"\n",
    "                \"Make the information well formatted and easy to read.\"\n",
    "            )\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the details of the created thread to check its properties.\n",
    "print(super_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the newly created thread to add tool resources, specifically linking the uploaded file.\n",
    "super_updated_thread = client.beta.threads.update(\n",
    "    thread_id=super_thread.id,  # Use the ID of the newly created thread.\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]  # Link the uploaded file to the code interpreter tool.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the details of the updated thread to check its properties.\n",
    "print(super_updated_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the output from the assistant.\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=super_updated_thread.id,  # Use the ID of the updated thread.\n",
    "    assistant_id=assistant.id,  # Use the ID of the assistant.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler to process events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Results Output\n",
    "\n",
    "We may also have images produced as well from the Code Interpreter output. Handling this can be tricky and getting it in the right sequence is pretty difficult. Here is some sample code that will assist but I don't pretend to be good at the interface stuff. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a thread to send a message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a one paragraph summary of the file penguins_size.csv. With at least one small table of data and one visualization.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=assistant_thread.id, run_id=run.id))\n",
    "\n",
    "content_blocks = []\n",
    "\n",
    "# Process each message\n",
    "for message in messages:\n",
    "    # Process each content block in the message\n",
    "    for content_block in message.content:\n",
    "        if content_block.type == 'text':\n",
    "            text_content = content_block.text\n",
    "            annotations = text_content.annotations\n",
    "            citations = []\n",
    "            for index, annotation in enumerate(annotations):\n",
    "                # Replace the text with a footnote\n",
    "                text_content.value = text_content.value.replace(annotation.text, f' [{index}]')\n",
    "                # Gather citations based on annotation attributes\n",
    "                if hasattr(annotation, 'file_citation'):\n",
    "                    file_citation = annotation.file_citation\n",
    "                    cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                    citations.append(f'[{index}] {file_citation.quote} from {cited_file.filename}')\n",
    "                elif hasattr(annotation, 'file_path'):\n",
    "                    file_path = annotation.file_path\n",
    "                    cited_file = client.files.retrieve(file_path.file_id)\n",
    "                    citations.append(f'[{index}] Click <here> to download {cited_file.filename}')\n",
    "            # Add footnotes to the end of the message before displaying to user\n",
    "            text_content.value += '\\n' + '\\n'.join(citations)\n",
    "            # Convert Markdown to HTML and append to content_blocks\n",
    "            content_blocks.append(markdown2.markdown(text_content.value, extras=[\"tables\"]))\n",
    "\n",
    "        elif content_block.type == 'image_file':\n",
    "            image_file = content_block.image_file\n",
    "            file_info = client.files.retrieve(image_file.file_id)\n",
    "            image_content = client.files.content(file_info.id).content\n",
    "            image_base64 = base64.b64encode(image_content).decode('utf-8')\n",
    "            # Append the image HTML to content_blocks\n",
    "            content_blocks.append(f'<img src=\"data:image/png;base64,{image_base64}\" width=\"700\" height=\"700\"><br>')\n",
    "\n",
    "# Join all content blocks into a single HTML string\n",
    "html_content = ''.join(content_blocks)\n",
    "\n",
    "# Display the combined content\n",
    "display(HTML(html_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Formatted Output\n",
    "I tried everything I could think of to get the images to stream inline with the text but it appears that doing so with Jupyter Notebook cells is very difficult. I finally had to throw in the towel. I did post to the forums to see if anyone had and answer but, apparently, no one did. You can see if someone finally answered here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "        self.image_counter = 0  # Counter for images\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        self.results.append(delta.value)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    @override\n",
    "    def on_image_file_created(self, image_file):\n",
    "        \"\"\"Handle the event when an image file is created.\"\"\"\n",
    "        print(f\"Image file created: {image_file.file_id}\")\n",
    "        # Retrieve the image file information and content\n",
    "        file_info = client.files.retrieve(image_file.file_id)\n",
    "        image_content = client.files.content(file_info.id).content\n",
    "        image_base64 = base64.b64encode(image_content).decode('utf-8')\n",
    "        # Append the image HTML to the results list\n",
    "        self.results.append(f'![Visualization {self.image_counter}](data:image/png;base64,{image_base64})\\n')\n",
    "        self.image_counter += 1\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text and image fragments stored in results to form the complete Markdown content\n",
    "        markdown_content = ''.join(self.results)\n",
    "        # Display the Markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "# Create a thread to send a message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Give me a one paragraph summary of the file penguins_size.csv. \"\n",
    "                \"With at least one small table of data and one visualization.\"\n",
    "            )\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Use the ID of the created thread\n",
    "    assistant_id=assistant.id,  # Use the ID of the assistant\n",
    "    event_handler=EventHandler(),  # Use the custom event handler to process events\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
