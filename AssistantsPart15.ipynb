{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.31.2 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from -r requirements.txt (line 4)) (1.31.2)\n",
      "Requirement already satisfied: pytz in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from -r requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (1.10.12)\n",
      "Requirement already satisfied: sniffio in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from openai==1.31.2->-r requirements.txt (line 4)) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.31.2->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: certifi in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.31.2->-r requirements.txt (line 4)) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.31.2->-r requirements.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.31.2->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: colorama in e:\\programfiles\\anaconda3\\envs\\normalprogramming\\lib\\site-packages (from tqdm>4->openai==1.31.2->-r requirements.txt (line 4)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handler class to handle events related to streaming output from the assistant\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nASSISTANT MESSAGE >\\n\", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nASSISTANT MESSAGE >\\n{tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_GtoNnhX1Wkgpsr4SfxZ5xn6Y', created_at=1717707009, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-aubKXKYvgIqRGBNIIqGp5tkA', bytes=13519, created_at=1717716265, filename='penguins_size.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(assistant_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_GtoNnhX1Wkgpsr4SfxZ5xn6Y', created_at=1717707009, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-aubKXKYvgIqRGBNIIqGp5tkA']), file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a thread to send message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT MESSAGE >\n",
      "Here is a concise summary of the penguin data:\n",
      "\n",
      "- **Total Entries:** 344\n",
      "- **Columns and non-null counts:**\n",
      "  - `species`: 344 (Three unique species: Adelie, Chinstrap, Gentoo)\n",
      "  - `island`: 344 (Three unique islands: Biscoe, Dream, Torgersen)\n",
      "  - `culmen_length_mm`: 342 (length of the bill, mean: 43.92 mm, range: 32.1 - 59.6 mm)\n",
      "  - `culmen_depth_mm`: 342 (depth of the bill, mean: 17.15 mm, range: 13.1 - 21.5 mm)\n",
      "  - `flipper_length_mm`: 342 (length of the flipper, mean: 200.92 mm, range: 172 - 231 mm)\n",
      "  - `body_mass_g`: 342 (body mass, mean: 4201.75 g, range: 2700 - 6300 g)\n",
      "  - `sex`: 334 (MALE, FEMALE)\n",
      "\n",
      "The dataset contains measurements related to penguins' physical features from different islands. The data includes some missing values in the `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g`, and `sex` columns.\n",
      "\n",
      "Would you like any specific analysis or visualization of this data?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant. \n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-fEyocpUVgvY1tdBm8VJUwYfe', bytes=43599, created_at=1717717460, filename='daily-bike-share.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(thread_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_vt5Sm3pO7Y2qKEyHZjKOiNXG', created_at=1717717633, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_vt5Sm3pO7Y2qKEyHZjKOiNXG', created_at=1717717633, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-fEyocpUVgvY1tdBm8VJUwYfe']), file_search=None))\n"
     ]
    }
   ],
   "source": [
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(updated_thread)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
