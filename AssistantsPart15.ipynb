{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\"\"\"\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        self.results.append(text)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\"\"\"\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "                self.results.append(delta.code_interpreter.input)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "                for output in delta.code_interpreter.outputs or []:  # Adding a safeguard\n",
    "                    if output.type == \"logs\":\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                        self.results.append(output.logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_nZpzQEtLhmpyx15fI44VjqVH', created_at=1718456112, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-XTz2oAJhhoIAdmKZiEzZbV6a', bytes=13519, created_at=1718456112, filename='penguins_size.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(assistant_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_nZpzQEtLhmpyx15fI44VjqVH', created_at=1718456112, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-XTz2oAJhhoIAdmKZiEzZbV6a']), file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant tool > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the uploaded CSV file\n",
      "file_path = '/mnt/data/file-XTz2oAJhhoIAdmKZiEzZbV6a'\n",
      "penguins_data = pd.read_csv(file_path)\n",
      "\n",
      "# Display a summary of the data\n",
      "summary = penguins_data.describe(include='all')\n",
      "summary\n",
      "assistant text > The `penguins_size.csv` file contains data on penguins with the following columns:\n",
      "\n",
      "1. **species**: The species of the penguin (Adelie, Gentoo, Chinstrap). There are 3 unique species in the dataset.\n",
      "2. **island**: The island where the penguin was found (Biscoe, Dream, Torgersen). There are 3 unique islands in the dataset.\n",
      "3. **culmen_length_mm**: The length of the culmen (bill) in millimeters.\n",
      "   - Count: 342\n",
      "   - Mean: 43.92 mm\n",
      "   - Standard Deviation: 5.46 mm\n",
      "   - Min: 32.1 mm\n",
      "   - Max: 59.6 mm\n",
      "4. **culmen_depth_mm**: The depth of the culmen (bill) in millimeters.\n",
      "   - Count: 342\n",
      "   - Mean: 17.15 mm\n",
      "   - Standard Deviation: 1.97 mm\n",
      "   - Min: 13.1 mm\n",
      "   - Max: 21.5 mm\n",
      "5. **flipper_length_mm**: The length of the flipper in millimeters.\n",
      "   - Count: 342\n",
      "   - Mean: 200.92 mm\n",
      "   - Standard Deviation: 14.06 mm\n",
      "   - Min: 172 mm\n",
      "   - Max: 231 mm\n",
      "6. **body_mass_g**: The body mass of the penguin in grams.\n",
      "   - Count: 342\n",
      "   - Mean: 4201.75 g\n",
      "   - Standard Deviation: 801.95 g\n",
      "   - Min: 2700 g\n",
      "   - Max: 6300 g\n",
      "7. **sex**: The sex of the penguin (MALE, FEMALE).\n",
      "   - Count: 334\n",
      "   - 3 unique values (including NaN/missing values)\n",
      "\n",
      "The dataset contains some missing values in the columns `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g`, and `sex`. The island and species columns are categorical data, while the other columns are numerical measurements."
     ]
    }
   ],
   "source": [
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Output\n",
    "What if we want to format the markdown output? There are two ways to do it. The easy way is to just let the output render without streaming and format it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The file `penguins_size.csv` contains data on various physical measurements of penguins. Here is a summary of the dataset:\n",
       "\n",
       "### Shape\n",
       "- The dataset contains 344 entries (rows) and 7 columns.\n",
       "\n",
       "### Columns\n",
       "- `species`: Type of penguin species (categorical)\n",
       "- `island`: Location/island where the penguin was observed (categorical)\n",
       "- `culmen_length_mm`: Length of the bill in millimeters (numerical)\n",
       "- `culmen_depth_mm`: Depth of the bill in millimeters (numerical)\n",
       "- `flipper_length_mm`: Length of the flipper in millimeters (numerical)\n",
       "- `body_mass_g`: Weight of the penguin in grams (numerical)\n",
       "- `sex`: Gender of the penguin (categorical)\n",
       "\n",
       "### Information\n",
       "- `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, and `body_mass_g` columns have 342 non-null values (indicating missing data in 2 entries).\n",
       "- `sex` column has 334 non-null values (indicating missing data in 10 entries).\n",
       "\n",
       "### Descriptive Statistics\n",
       "- **culmen_length_mm**:\n",
       "  - Mean: 43.92 mm\n",
       "  - Std Dev: 5.46 mm\n",
       "  - Min: 32.1 mm\n",
       "  - Max: 59.6 mm\n",
       "  \n",
       "- **culmen_depth_mm**:\n",
       "  - Mean: 17.15 mm\n",
       "  - Std Dev: 1.97 mm\n",
       "  - Min: 13.1 mm\n",
       "  - Max: 21.5 mm\n",
       "  \n",
       "- **flipper_length_mm**:\n",
       "  - Mean: 200.92 mm\n",
       "  - Std Dev: 14.06 mm\n",
       "  - Min: 172 mm\n",
       "  - Max: 231 mm\n",
       "  \n",
       "- **body_mass_g**:\n",
       "  - Mean: 4201.75 g\n",
       "  - Std Dev: 801.95 g\n",
       "  - Min: 2700 g\n",
       "  - Max: 6300 g"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need a thread to send message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=assistant_thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "display(Markdown(message_content.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hard\" way is to stream the output and update the display while streaming to show the formatted text. This is what ChatGPT does when you use it. This will require modifying our event handler to be more streamlined, formatting output, and updating our display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start by loading the contents of the file \"penguins_size.csv\" to examine its structure and understand its contents. I will read the file and provide a summary.\n",
      "\n",
      "Let's begin by loading and inspecting the data.The \"penguins_size.csv\" dataset consists of 344 entries (or rows) and 7 columns. Here's a brief summary of the columns:\n",
      "\n",
      "1. **species**: The species of the penguin (categorical data).\n",
      "2. **island**: The island where the penguin was found (categorical data).\n",
      "3. **culmen_length_mm**: The length of the penguin's culmen (bill) in millimeters (continuous data).\n",
      "4. **culmen_depth_mm**: The depth of the penguin's culmen (bill) in millimeters (continuous data).\n",
      "5. **flipper_length_mm**: The length of the penguin's flipper in millimeters (continuous data).\n",
      "6. **body_mass_g**: The body mass of the penguin in grams (continuous data).\n",
      "7. **sex**: The sex of the penguin (categorical data).\n",
      "\n",
      "### Data Information:\n",
      "- There are some missing values (`NaN`), particularly in the columns `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g`, and `sex`.\n",
      "- The data types for these columns are a mix of object (for categorical data) and float64 (for continuous data).\n",
      "\n",
      "Let me also give you basic statistics of the dataset to provide more insight.Here are some key statistics about the dataset:\n",
      "\n",
      "### Species\n",
      "- **Unique values**: 3 (Adelie, Gentoo, Chinstrap)\n",
      "- **Most frequent value**: Adelie (152 occurrences)\n",
      "\n",
      "### Island\n",
      "- **Unique values**: 3 (Biscoe, Dream, Torgersen)\n",
      "- **Most frequent value**: Biscoe (168 occurrences)\n",
      "\n",
      "### Culmen Length (mm)\n",
      "- **Count (Non-null values)**: 342\n",
      "- **Mean**: 43.92 mm\n",
      "- **Standard Deviation**: 5.46 mm\n",
      "- **Min**: 32.1 mm\n",
      "- **25th Percentile**: 39.23 mm\n",
      "- **Median (50th Percentile)**: 44.45 mm\n",
      "- **75th Percentile**: 48.50 mm\n",
      "- **Max**: 59.6 mm\n",
      "\n",
      "### Culmen Depth (mm)\n",
      "- **Count (Non-null values)**: 342\n",
      "- **Mean**: 17.15 mm\n",
      "- **Standard Deviation**: 1.97 mm\n",
      "- **Min**: 13.1 mm\n",
      "- **25th Percentile**: 15.6 mm\n",
      "- **Median (50th Percentile)**: 17.3 mm\n",
      "- **75th Percentile**: 18.7 mm\n",
      "- **Max**: 21.5 mm\n",
      "\n",
      "### Flipper Length (mm)\n",
      "- **Count (Non-null values)**: 342\n",
      "- **Mean**: 200.92 mm\n",
      "- **Standard Deviation**: 14.06 mm\n",
      "- **Min**: 172 mm\n",
      "- **25th Percentile**: 190 mm\n",
      "- **Median (50th Percentile)**: 197 mm\n",
      "- **75th Percentile**: 213 mm\n",
      "- **Max**: 231 mm\n",
      "\n",
      "### Body Mass (g)\n",
      "- **Count (Non-null values)**: 342\n",
      "- **Mean**: 4201.75 g\n",
      "- **Standard Deviation**: 801.95 g\n",
      "- **Min**: 2700 g\n",
      "- **25th Percentile**: 3550 g\n",
      "- **Median (50th Percentile)**: 4050 g\n",
      "- **75th Percentile**: 4750 g\n",
      "- **Max**: 6300 g\n",
      "\n",
      "### Sex\n",
      "- **Unique values**: 3 (MALE, FEMALE, .)\n",
      "- **Most frequent value**: MALE (168 occurrences)\n",
      "- **Non-null entries**: 334\n",
      "\n",
      "The presence of missing values in this dataset indicates that some rows have incomplete information, especially in the columns related to measurements and sex.\n",
      "\n",
      "If you need further analysis or specific details, feel free to ask!"
     ]
    }
   ],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(thread_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the daily-bike-share.csv file.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(updated_thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it against a new assistant and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the client library.\n",
    "thread_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant Using Thread Data\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=updated_thread.id,\n",
    "    assistant_id=thread_assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Results from files in Assistants and Threads\n",
    "\n",
    "Let's see what happens if we use an assistant with a file and a thread with a file together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the penguins-size.csv and daily-bike-share.csv files.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(super_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_updated_thread = client.beta.threads.update(\n",
    "    thread_id=super_thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(super_updated_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=super_updated_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Results Output\n",
    "\n",
    "We may have other things that are produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create the assistant with the Code Interpreter tool\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data analyst. When provided with a file, analyze the data and generate visualizations.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a thread to start the analysis\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please analyze the data in the uploaded file and generate relevant visualizations.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fetch the results of the analysis\n",
    "response = client.beta.threads.retrieve(thread.id)\n",
    "\n",
    "# Convert the response to a dictionary to access its attributes\n",
    "response_dict = response.to_dict()\n",
    "\n",
    "# Debug: Print the entire response to understand its structure\n",
    "print(json.dumps(response_dict, indent=2))\n",
    "\n",
    "# Access messages from the thread\n",
    "messages = response_dict.get('messages', [])\n",
    "for message in messages:\n",
    "    content = message.get('content', '')\n",
    "    print(content)\n",
    "    \n",
    "    # If the response includes images, download and save them\n",
    "    if \"image_file\" in message:\n",
    "        image_file_id = message[\"image_file\"][\"file_id\"]\n",
    "        image_data = client.files.content(image_file_id)\n",
    "        with open(\"analysis_image.png\", \"wb\") as image_file:\n",
    "            image_file.write(image_data.read())\n",
    "        # Display the image in the notebook\n",
    "        display(Image(\"analysis_image.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
