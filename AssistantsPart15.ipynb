{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\"\"\"\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        self.results.append(text)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\"\"\"\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "                self.results.append(delta.code_interpreter.input)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "                for output in delta.code_interpreter.outputs or []:  # Adding a safeguard\n",
    "                    if output.type == \"logs\":\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                        self.results.append(output.logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_NJXSq3fabZZsjUPd3VKQJ7Wr', created_at=1718456940, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-WgMygp342PBPHUaAkRhMQURl', bytes=13519, created_at=1718456940, filename='penguins_size.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(assistant_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_NJXSq3fabZZsjUPd3VKQJ7Wr', created_at=1718456940, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-WgMygp342PBPHUaAkRhMQURl']), file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant tool > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file\n",
      "file_path = '/mnt/data/file-WgMygp342PBPHUaAkRhMQURl'\n",
      "penguins_df = pd.read_csv(file_path)\n",
      "\n",
      "# Get a summary of the DataFrame\n",
      "summary = {\n",
      "    'columns': penguins_df.columns.tolist(),\n",
      "    'head': penguins_df.head(),\n",
      "    'info': penguins_df.info(),\n",
      "    'description': penguins_df.describe()\n",
      "}\n",
      "\n",
      "summary\n",
      "\n",
      "output >\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   culmen_length_mm   342 non-null    float64\n",
      " 3   culmen_depth_mm    342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                334 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n",
      "\n",
      "\n",
      "assistant text > The file `penguins_size.csv` contains data on penguins with the following summary:\n",
      "\n",
      "### Columns:\n",
      "1. **species** (object): The species of the penguin.\n",
      "2. **island** (object): The island where the penguin was observed.\n",
      "3. **culmen_length_mm** (float64): The length of the penguin's culmen (bill) in millimeters.\n",
      "4. **culmen_depth_mm** (float64): The depth of the penguin's culmen (bill) in millimeters.\n",
      "5. **flipper_length_mm** (float64): The length of the penguin's flipper in millimeters.\n",
      "6. **body_mass_g** (float64): The body mass of the penguin in grams.\n",
      "7. **sex** (object): The sex of the penguin.\n",
      "\n",
      "### Data Information:\n",
      "- There are 344 entries in total.\n",
      "- Most columns have 342 non-null entries, except for the **sex** column which has 334 non-null entries.\n",
      "- The missing values are found in the **culmen_length_mm**, **culmen_depth_mm**, **flipper_length_mm**, **body_mass_g**, and **sex** columns.\n",
      "\n",
      "### Sample Data (first 5 rows):\n",
      "| species  | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
      "|----------|-----------|-------------------|-----------------|-------------------|-------------|-------|\n",
      "| Adelie   | Torgersen | 39.1              | 18.7            | 181.0             | 3750.0      | MALE  |\n",
      "| Adelie   | Torgersen | 39.5              | 17.4            | 186.0             | 3800.0      | FEMALE|\n",
      "| Adelie   | Torgersen | 40.3              | 18.0            | 195.0             | 3250.0      | FEMALE|\n",
      "| Adelie   | Torgersen | NaN               | NaN             | NaN               | NaN         | NaN   |\n",
      "| Adelie   | Torgersen | 36.7              | 19.3            | 193.0             | 3450.0      | FEMALE|\n",
      "\n",
      "### Descriptive Statistics:\n",
      "- **culmen_length_mm**: \n",
      "  - Mean: 43.92 mm\n",
      "  - Standard Deviation: 5.46 mm\n",
      "  - Min: 32.1 mm\n",
      "  - Max: 59.6 mm\n",
      "- **culmen_depth_mm**: \n",
      "  - Mean: 17.15 mm\n",
      "  - Standard Deviation: 1.97 mm\n",
      "  - Min: 13.1 mm\n",
      "  - Max: 21.5 mm\n",
      "- **flipper_length_mm**: \n",
      "  - Mean: 200.92 mm\n",
      "  - Standard Deviation: 14.06 mm\n",
      "  - Min: 172 mm\n",
      "  - Max: 231 mm\n",
      "- **body_mass_g**: \n",
      "  - Mean: 4201.75 g\n",
      "  - Standard Deviation: 801.95 g\n",
      "  - Min: 2700 g\n",
      "  - Max: 6300 g\n",
      "\n",
      "This summary provides an overview of the data file `penguins_size.csv`, highlighting the key aspects and statistics of the dataset."
     ]
    }
   ],
   "source": [
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Output\n",
    "What if we want to format the markdown output? There are two ways to do it. The easy way is to just let the output render without streaming and format it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The `penguins_size.csv` file contains data about penguins, with the following key details:\n",
       "\n",
       "- **Number of entries:** 344\n",
       "- **Columns:** 7\n",
       "\n",
       "The columns are:\n",
       "1. **species:** The species of the penguin (e.g., Adelie, Gentoo, Chinstrap).\n",
       "2. **island:** The island where the penguin was observed (e.g., Torgersen, Biscoe, Dream).\n",
       "3. **culmen_length_mm:** The length of the penguin's culmen (bill) in millimeters.\n",
       "4. **culmen_depth_mm:** The depth of the penguin's culmen in millimeters.\n",
       "5. **flipper_length_mm:** The length of the penguin's flipper in millimeters.\n",
       "6. **body_mass_g:** The body mass of the penguin in grams.\n",
       "7. **sex:** The sex of the penguin (e.g., MALE, FEMALE).\n",
       "\n",
       "**Notes:**\n",
       "- The columns `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, and `body_mass_g` have some missing values.\n",
       "- The `sex` column has more missing values compared to other columns.\n",
       "\n",
       "Here is a snapshot of the first few rows of the dataset:\n",
       "| species | island   | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
       "|---------|----------|------------------|-----------------|-------------------|-------------|-------|\n",
       "| Adelie  | Torgersen| 39.1             | 18.7            | 181.0             | 3750.0      | MALE  |\n",
       "| Adelie  | Torgersen| 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE|\n",
       "| Adelie  | Torgersen| 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE|\n",
       "| Adelie  | Torgersen| NaN              | NaN             | NaN               | NaN         | NaN   |\n",
       "| Adelie  | Torgersen| 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE|\n",
       "\n",
       "This dataset provides measurements and attributes for different penguin species observed on different islands."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need a thread to send message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=assistant_thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "display(Markdown(message_content.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hard\" way is to stream the output and update the display while streaming to show the formatted text. This is what ChatGPT does when you use it. This will require modifying our event handler to be more streamlined, formatting output, and updating our display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file `penguins_size.csv` contains data on penguins and includes the following details:\n",
      "\n",
      "- There are a total of 344 entries in the dataset.\n",
      "- There are 7 columns in the dataset:\n",
      "  1. **species**: The species of the penguin (e.g., Adelie).\n",
      "  2. **island**: The island where the penguin was observed (e.g., Torgersen).\n",
      "  3. **culmen_length_mm**: The length of the culmen (the upper ridge of a bird's beak) in millimeters.\n",
      "  4. **culmen_depth_mm**: The depth of the culmen in millimeters.\n",
      "  5. **flipper_length_mm**: The length of the penguin's flipper in millimeters.\n",
      "  6. **body_mass_g**: The body mass of the penguin in grams.\n",
      "  7. **sex**: The sex of the penguin (e.g., MALE, FEMALE).\n",
      "\n",
      "### Observations:\n",
      "- Columns **culmen_length_mm**, **culmen_depth_mm**, **flipper_length_mm**, and **body_mass_g** have 342 non-null entries.\n",
      "- The **sex** column has 334 non-null entries.\n",
      "\n",
      "Here is a preview of the first few rows of the dataset:\n",
      "\n",
      "| species | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex    |\n",
      "|---------|-----------|------------------|-----------------|-------------------|-------------|--------|\n",
      "| Adelie  | Torgersen | 39.1             | 18.7            | 181.0             | 3750.0      | MALE   |\n",
      "| Adelie  | Torgersen | 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE |\n",
      "| Adelie  | Torgersen | 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE |\n",
      "| Adelie  | Torgersen | NaN              | NaN             | NaN               | NaN         | NaN    |\n",
      "| Adelie  | Torgersen | 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE |\n",
      "\n",
      "Would you like to perform any specific analysis or operations on this dataset?"
     ]
    }
   ],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a summary of the dataset `penguins_size.csv`:\n",
       "\n",
       "### Summary Statistics\n",
       "|                    | Culmen Length (mm) | Culmen Depth (mm) | Flipper Length (mm) | Body Mass (g) |\n",
       "|--------------------|--------------------|-------------------|---------------------|--------------|\n",
       "| **Count**            | 342                | 342               | 342                 | 342          |\n",
       "| **Mean**             | 43.92              | 17.15             | 200.92              | 4201.75      |\n",
       "| **Standard Deviation**  | 5.46               | 1.97              | 14.06               | 801.95       |\n",
       "| **Minimum**          | 32.10              | 13.10             | 172.00              | 2700.00      |\n",
       "| **25th Percentile**   | 39.23              | 15.60             | 190.00              | 3550.00      |\n",
       "| **Median (50th %ile)**| 44.45              | 17.30             | 197.00              | 4050.00      |\n",
       "| **75th Percentile**   | 48.50              | 18.70             | 213.00              | 4750.00      |\n",
       "| **Maximum**          | 59.60              | 21.50             | 231.00              | 6300.00      |\n",
       "\n",
       "### Sample Data\n",
       "Here are the first few rows of the dataset:\n",
       "\n",
       "|   | species | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
       "|---|---------|-----------|------------------|-----------------|-------------------|-------------|-------|\n",
       "| 0 | Adelie  | Torgersen | 39.1             | 18.7            | 181.0             | 3750.0      | MALE  |\n",
       "| 1 | Adelie  | Torgersen | 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE|\n",
       "| 2 | Adelie  | Torgersen | 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE|\n",
       "| 3 | Adelie  | Torgersen | NaN              | NaN             | NaN               | NaN         | NaN   |\n",
       "| 4 | Adelie  | Torgersen | 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE|\n",
       "\n",
       "This dataset contains measurements of different species of penguins, including their culmen (bill) length and depth, flipper length, body mass, and sex."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        self.results.append(delta.value)\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv. With one small table of data.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(thread_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the daily-bike-share.csv file.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(updated_thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it against a new assistant and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the client library.\n",
    "thread_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant Using Thread Data\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=updated_thread.id,\n",
    "    assistant_id=thread_assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Results from files in Assistants and Threads\n",
    "\n",
    "Let's see what happens if we use an assistant with a file and a thread with a file together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the penguins-size.csv and daily-bike-share.csv files.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(super_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_updated_thread = client.beta.threads.update(\n",
    "    thread_id=super_thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(super_updated_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=super_updated_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Results Output\n",
    "\n",
    "We may have other things that are produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create the assistant with the Code Interpreter tool\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data analyst. When provided with a file, analyze the data and generate visualizations.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a thread to start the analysis\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please analyze the data in the uploaded file and generate relevant visualizations.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fetch the results of the analysis\n",
    "response = client.beta.threads.retrieve(thread.id)\n",
    "\n",
    "# Convert the response to a dictionary to access its attributes\n",
    "response_dict = response.to_dict()\n",
    "\n",
    "# Debug: Print the entire response to understand its structure\n",
    "print(json.dumps(response_dict, indent=2))\n",
    "\n",
    "# Access messages from the thread\n",
    "messages = response_dict.get('messages', [])\n",
    "for message in messages:\n",
    "    content = message.get('content', '')\n",
    "    print(content)\n",
    "    \n",
    "    # If the response includes images, download and save them\n",
    "    if \"image_file\" in message:\n",
    "        image_file_id = message[\"image_file\"][\"file_id\"]\n",
    "        image_data = client.files.content(image_file_id)\n",
    "        with open(\"analysis_image.png\", \"wb\") as image_file:\n",
    "            image_file.write(image_data.read())\n",
    "        # Display the image in the notebook\n",
    "        display(Image(\"analysis_image.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
