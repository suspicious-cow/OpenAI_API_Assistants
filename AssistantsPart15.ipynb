{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"Handle the event when text is first created.\"\"\"\n",
    "        print(\"\\nassistant text > \", end=\"\", flush=True)\n",
    "        self.results.append(text)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "        self.results.append(delta.value)\n",
    "\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"Handle the event when a tool call is created.\"\"\"\n",
    "        print(f\"\\nassistant tool > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a delta (update) in a tool call.\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "                self.results.append(delta.code_interpreter.input)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(\"\\n\\noutput >\", flush=True)\n",
    "                for output in delta.code_interpreter.outputs or []:  # Adding a safeguard\n",
    "                    if output.type == \"logs\":\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                        self.results.append(output.logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_NJXSq3fabZZsjUPd3VKQJ7Wr', created_at=1718456940, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-WgMygp342PBPHUaAkRhMQURl', bytes=13519, created_at=1718456940, filename='penguins_size.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(assistant_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_NJXSq3fabZZsjUPd3VKQJ7Wr', created_at=1718456940, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-WgMygp342PBPHUaAkRhMQURl']), file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant tool > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file\n",
      "file_path = '/mnt/data/file-WgMygp342PBPHUaAkRhMQURl'\n",
      "penguins_df = pd.read_csv(file_path)\n",
      "\n",
      "# Get a summary of the DataFrame\n",
      "summary = {\n",
      "    'columns': penguins_df.columns.tolist(),\n",
      "    'head': penguins_df.head(),\n",
      "    'info': penguins_df.info(),\n",
      "    'description': penguins_df.describe()\n",
      "}\n",
      "\n",
      "summary\n",
      "\n",
      "output >\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   culmen_length_mm   342 non-null    float64\n",
      " 3   culmen_depth_mm    342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                334 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n",
      "\n",
      "\n",
      "assistant text > The file `penguins_size.csv` contains data on penguins with the following summary:\n",
      "\n",
      "### Columns:\n",
      "1. **species** (object): The species of the penguin.\n",
      "2. **island** (object): The island where the penguin was observed.\n",
      "3. **culmen_length_mm** (float64): The length of the penguin's culmen (bill) in millimeters.\n",
      "4. **culmen_depth_mm** (float64): The depth of the penguin's culmen (bill) in millimeters.\n",
      "5. **flipper_length_mm** (float64): The length of the penguin's flipper in millimeters.\n",
      "6. **body_mass_g** (float64): The body mass of the penguin in grams.\n",
      "7. **sex** (object): The sex of the penguin.\n",
      "\n",
      "### Data Information:\n",
      "- There are 344 entries in total.\n",
      "- Most columns have 342 non-null entries, except for the **sex** column which has 334 non-null entries.\n",
      "- The missing values are found in the **culmen_length_mm**, **culmen_depth_mm**, **flipper_length_mm**, **body_mass_g**, and **sex** columns.\n",
      "\n",
      "### Sample Data (first 5 rows):\n",
      "| species  | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
      "|----------|-----------|-------------------|-----------------|-------------------|-------------|-------|\n",
      "| Adelie   | Torgersen | 39.1              | 18.7            | 181.0             | 3750.0      | MALE  |\n",
      "| Adelie   | Torgersen | 39.5              | 17.4            | 186.0             | 3800.0      | FEMALE|\n",
      "| Adelie   | Torgersen | 40.3              | 18.0            | 195.0             | 3250.0      | FEMALE|\n",
      "| Adelie   | Torgersen | NaN               | NaN             | NaN               | NaN         | NaN   |\n",
      "| Adelie   | Torgersen | 36.7              | 19.3            | 193.0             | 3450.0      | FEMALE|\n",
      "\n",
      "### Descriptive Statistics:\n",
      "- **culmen_length_mm**: \n",
      "  - Mean: 43.92 mm\n",
      "  - Standard Deviation: 5.46 mm\n",
      "  - Min: 32.1 mm\n",
      "  - Max: 59.6 mm\n",
      "- **culmen_depth_mm**: \n",
      "  - Mean: 17.15 mm\n",
      "  - Standard Deviation: 1.97 mm\n",
      "  - Min: 13.1 mm\n",
      "  - Max: 21.5 mm\n",
      "- **flipper_length_mm**: \n",
      "  - Mean: 200.92 mm\n",
      "  - Standard Deviation: 14.06 mm\n",
      "  - Min: 172 mm\n",
      "  - Max: 231 mm\n",
      "- **body_mass_g**: \n",
      "  - Mean: 4201.75 g\n",
      "  - Standard Deviation: 801.95 g\n",
      "  - Min: 2700 g\n",
      "  - Max: 6300 g\n",
      "\n",
      "This summary provides an overview of the data file `penguins_size.csv`, highlighting the key aspects and statistics of the dataset."
     ]
    }
   ],
   "source": [
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Output\n",
    "What if we want to format the markdown output? There are two ways to do it. The \"easy\" way is to just let the output render without streaming and format it afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of the Dataset\n",
       "\n",
       "The `penguins_size.csv` dataset contains measurements and characteristics of penguins. Here is a summary of the dataset:\n",
       "\n",
       "- **Total Entries**: 344\n",
       "- **Columns**: 7\n",
       "- **Non-null Entries**: \n",
       "  - `species`: 344 non-null\n",
       "  - `island`: 344 non-null\n",
       "  - `culmen_length_mm`: 342 non-null\n",
       "  - `culmen_depth_mm`: 342 non-null\n",
       "  - `flipper_length_mm`: 342 non-null\n",
       "  - `body_mass_g`: 342 non-null\n",
       "  - `sex`: 334 non-null\n",
       "- **Data Types**: \n",
       "  - 4 columns of type float64\n",
       "  - 3 columns of type object (categorical data)\n",
       "\n",
       "### Column Meanings\n",
       "\n",
       "- **species**: Species of the penguin (e.g., Adelie, Chinstrap, Gentoo)\n",
       "- **island**: Island where the penguin was observed (e.g., Biscoe, Dream, Torgersen)\n",
       "- **culmen_length_mm**: Length of the culmen (mm)\n",
       "- **culmen_depth_mm**: Depth of the culmen (mm)\n",
       "- **flipper_length_mm**: Length of the flipper (mm)\n",
       "- **body_mass_g**: Body mass (g)\n",
       "- **sex**: Sex of the penguin (e.g., MALE, FEMALE)\n",
       "\n",
       "### Data Sample\n",
       "\n",
       "Here is a small sample of the dataset:\n",
       "\n",
       "| species | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex    |\n",
       "|---------|-----------|------------------|-----------------|-------------------|-------------|--------|\n",
       "| Adelie  | Torgersen | 39.1             | 18.7            | 181.0             | 3750.0      | MALE   |\n",
       "| Adelie  | Torgersen | 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE |\n",
       "| Adelie  | Torgersen | 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE |\n",
       "| Adelie  | Torgersen | NaN              | NaN             | NaN               | NaN         | NaN    |\n",
       "| Adelie  | Torgersen | 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE |\n",
       "\n",
       "### Statistical Summary\n",
       "\n",
       "|                     |      Value   |\n",
       "|---------------------|--------------|\n",
       "| **Mean Culmen Length (mm)**       | 43.92  |\n",
       "| **Mean Culmen Depth (mm)**        | 17.15  |\n",
       "| **Mean Flipper Length (mm)**      | 200.92 |\n",
       "| **Mean Body Mass (g)**            | 4201.75|\n",
       "| **Most Frequent Species**         | Adelie |\n",
       "| **Most Frequent Island**          | Biscoe |\n",
       "| **Most Frequent Sex**             | MALE   |\n",
       "\n",
       "If you need more detailed information or additional analysis, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need a thread to send message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.  With at least one small table of data.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=assistant_thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=assistant_thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "display(Markdown(message_content.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hard\" way is to stream the output and update the display while streaming to show the formatted text. This is what ChatGPT does when you use it. This will require modifying our event handler to be more streamlined, formatting output, and updating our display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of the penguins_size.csv File\n",
       "\n",
       "The dataset contains the following columns:\n",
       "1. **species**: The species of the penguin (Adelie, Chinstrap, Gentoo).\n",
       "2. **island**: The island where the penguin was observed (Biscoe, Dream, Torgersen).\n",
       "3. **culmen_length_mm**: The length of the culmen (bill) in millimeters.\n",
       "4. **culmen_depth_mm**: The depth of the culmen (bill) in millimeters.\n",
       "5. **flipper_length_mm**: The length of the flipper in millimeters.\n",
       "6. **body_mass_g**: The body mass of the penguin in grams.\n",
       "7. **sex**: The sex of the penguin (MALE, FEMALE).\n",
       "\n",
       "#### Summary Statistics:\n",
       "- **species**: 3 unique species with 344 entries.\n",
       "- **island**: 3 unique islands with 344 entries.\n",
       "- **culmen_length_mm**: 342 entries, mean of 43.92 mm, standard deviation of 5.46 mm, min of 32.1 mm, max of 59.6 mm.\n",
       "- **culmen_depth_mm**: 342 entries, mean of 17.15 mm, standard deviation of 1.97 mm, min of 13.1 mm, max of 21.5 mm.\n",
       "- **flipper_length_mm**: 342 entries, mean of 200.92 mm, standard deviation of 14.06 mm, min of 172 mm, max of 231 mm.\n",
       "- **body_mass_g**: 342 entries, mean of 4201.75 g, standard deviation of 801.95 g, min of 2700 g, max of 6300 g.\n",
       "- **sex**: 334 entries, 3 unique values with 'MALE' being the most frequent.\n",
       "\n",
       "#### Sample Data:\n",
       "| species | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex   |\n",
       "|---------|-----------|------------------|-----------------|-------------------|-------------|-------|\n",
       "| Adelie  | Torgersen | 39.1             | 18.7            | 181.0             | 3750.0      | MALE  |\n",
       "| Adelie  | Torgersen | 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE|\n",
       "| Adelie  | Torgersen | 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE|\n",
       "| Adelie  | Torgersen | NaN              | NaN             | NaN               | NaN         | NaN   |\n",
       "| Adelie  | Torgersen | 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE|\n",
       "\n",
       "This dataset provides measurements for different penguin species observed on various islands. The measurements include physical attributes such as culmen length, depth, flipper length, and body mass, along with the sex of the penguins."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize the results list\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        self.results.append(delta.value)\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "# Your assistant code remains unchanged\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv. With at least one small table of data.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(thread_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the daily-bike-share.csv file.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(updated_thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it against a new assistant and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the client library.\n",
    "thread_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant Using Thread Data\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=updated_thread.id,\n",
    "    assistant_id=thread_assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Results from files in Assistants and Threads\n",
    "\n",
    "Let's see what happens if we use an assistant with a file and a thread with a file together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the penguins-size.csv and daily-bike-share.csv files.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(super_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_updated_thread = client.beta.threads.update(\n",
    "    thread_id=super_thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(super_updated_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=super_updated_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Results Output\n",
    "\n",
    "We may have other things that are produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create the assistant with the Code Interpreter tool\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data analyst. When provided with a file, analyze the data and generate visualizations.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a thread to start the analysis\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please analyze the data in the uploaded file and generate relevant visualizations.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fetch the results of the analysis\n",
    "response = client.beta.threads.retrieve(thread.id)\n",
    "\n",
    "# Convert the response to a dictionary to access its attributes\n",
    "response_dict = response.to_dict()\n",
    "\n",
    "# Debug: Print the entire response to understand its structure\n",
    "print(json.dumps(response_dict, indent=2))\n",
    "\n",
    "# Access messages from the thread\n",
    "messages = response_dict.get('messages', [])\n",
    "for message in messages:\n",
    "    content = message.get('content', '')\n",
    "    print(content)\n",
    "    \n",
    "    # If the response includes images, download and save them\n",
    "    if \"image_file\" in message:\n",
    "        image_file_id = message[\"image_file\"][\"file_id\"]\n",
    "        image_data = client.files.content(image_file_id)\n",
    "        with open(\"analysis_image.png\", \"wb\") as image_file:\n",
    "            image_file.write(image_data.read())\n",
    "        # Display the image in the notebook\n",
    "        display(Image(\"analysis_image.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
