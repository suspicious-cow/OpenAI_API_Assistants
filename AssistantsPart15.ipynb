{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15\n",
    "\n",
    "# Using Code Interpreter\n",
    "\n",
    "Universal code for the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to make sure you have all the packages needed\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI  # Used for interacting with OpenAI's API\n",
    "from typing_extensions import override  # Used for overriding methods in subclasses\n",
    "from openai import AssistantEventHandler  # Used for handling events related to OpenAI assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI class to interact with the API.\n",
    "# This assumes you have set the OPENAI_API_KEY environment variable.\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handler class to handle events related to streaming output from the assistant\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nASSISTANT MESSAGE >\\n\", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nASSISTANT MESSAGE >\\n{tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Assistant with Code Interpreter Enabled\n",
    "\n",
    "Our first step is to create an Assistant that can use Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_NhHQtzG0a3e3rOBM1CScNn03', created_at=1718452978, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Files to Code Interpreter\n",
    "\n",
    "There are a variety of ways to get files for Code Interpreter to use. \n",
    "- Assistant files - viewable by all runs that use the assistant.\n",
    "- Thread files - only viewable by runs that use the thread. \n",
    "\n",
    "Let's review the code for the two main approaches.\n",
    "\n",
    "### Getting Files to the Assistant\n",
    "\n",
    "First, you have to have a file that has been uploaded so we can pass it to our assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-3P2mhdFtnDTKpsxawxiWdFBS', bytes=13519, created_at=1718452978, filename='penguins_size.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "assistant_file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(assistant_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify our Assistant with the new file information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_NhHQtzG0a3e3rOBM1CScNn03', created_at=1718452978, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-3P2mhdFtnDTKpsxawxiWdFBS']), file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [assistant_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run a message and see if it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT MESSAGE >\n",
      "code_interpreter\n",
      "\n",
      "\n",
      "ASSISTANT MESSAGE >\n",
      "The dataset `penguins_size.csv` contains measurements and characteristics of 344 penguins. Hereâ€™s a summary of the file:\n",
      "\n",
      "1. **Data Columns and Types:**\n",
      "   - `species`: (object) The species of the penguin, with 3 unique species.\n",
      "   - `island`: (object) The island where the penguin was found, with 3 unique islands.\n",
      "   - `culmen_length_mm`: (float64) Length of the culmen (beak), with some missing values (342 non-null).\n",
      "   - `culmen_depth_mm`: (float64) Depth of the culmen (beak), with some missing values (342 non-null).\n",
      "   - `flipper_length_mm`: (float64) Length of the flipper, with some missing values (342 non-null).\n",
      "   - `body_mass_g`: (float64) Body mass of the penguin in grams, with some missing values (342 non-null).\n",
      "   - `sex`: (object) Sex of the penguin, with 3 unique values and some missing values (334 non-null).\n",
      "\n",
      "2. **Statistical Summary:**\n",
      "   - There are 3 species with `Adelie` being the most frequent.\n",
      "   - Penguins are found on 3 different islands, with `Biscoe` being the most common.\n",
      "   - `culmen_length_mm` ranges from 32.1 mm to 59.6 mm, with a mean of approximately 43.9 mm.\n",
      "   - `culmen_depth_mm` ranges from 13.1 mm to 21.5 mm, with a mean of approximately 17.2 mm.\n",
      "   - `flipper_length_mm` ranges from 172 mm to 231 mm, with a mean of approximately 200.9 mm.\n",
      "   - `body_mass_g` ranges from 2700 g to 6300 g, with a mean of approximately 4201.8 g.\n",
      "   - Regarding sex, `MALE` is the most common, but there are missing values.\n",
      "\n",
      "Would you like any specific analysis or visualization performed on this data?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Need a thread to send message and get output\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the file penguins_size.csv.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Files to the Thread\n",
    "\n",
    "First, we need a file uploaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-ja8z169Xf9X5mU248naSSheD', bytes=43599, created_at=1717720479, filename='daily-bike-share.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "thread_file = client.files.create(\n",
    "    file=open(\"./artifacts/daily-bike-share.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "print(thread_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a thread to attach the file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_Wrq2Tj1zHqTOT91mf41HVUFn', created_at=1717720480, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the daily-bike-share.csv file.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can update the thread with the file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_Wrq2Tj1zHqTOT91mf41HVUFn', created_at=1717720480, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-ja8z169Xf9X5mU248naSSheD']), file_search=None))\n"
     ]
    }
   ],
   "source": [
    "updated_thread = client.beta.threads.update(\n",
    "    thread_id=thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(updated_thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it against a new assistant and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_nikNl521MHGPe1CRxj0mrr1i', created_at=1717720458, description=None, instructions=' \\n        You are a helpful assistant.\\n    ', metadata={'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}, model='gpt-4o', name='Code Interpreter Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-QKiPf2QBRZdfVMkytsid5r2p']), file_search=None), top_p=1.0)\n",
      "\n",
      "\n",
      "\n",
      "Code Interpreter Assistant\n",
      "{'can_be_used_for_code_analysis': 'True', 'can_do_python': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant using the client library.\n",
    "thread_assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",\n",
    "    \n",
    "    name=\"Code Interpreter Assistant Using Thread Data\",  # Give the assistant a name.\n",
    "    \n",
    "    tools=[{\"type\": \"code_interpreter\"}], # Add the code interpreter capability to the assistant.\n",
    "    \n",
    "    metadata={  # Add metadata about the assistant's capabilities.\n",
    "        \"can_be_used_for_code_analysis\": \"True\",\n",
    "        \"can_do_python\": \"True\",\n",
    "    },\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Print the details of the created assistant to check its properties.\n",
    "print(assistant)  # Print the full assistant object.\n",
    "print(\"\\n\\n\")\n",
    "print(assistant.name)  # Print the name of the assistant.\n",
    "print(assistant.metadata)  # Print the metadata of the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT MESSAGE >\n",
      "code_interpreter\n",
      "\n",
      "\n",
      "ASSISTANT MESSAGE >\n",
      "The dataset \"daily-bike-share.csv\" contains 731 records and the following 13 columns. Below is a summary of each column:\n",
      "\n",
      "1. **day (integer)**:\n",
      "   - Count: 731\n",
      "   - Mean: 15.74\n",
      "   - Std: 8.81\n",
      "   - Min: 1\n",
      "   - 25th percentile: 8\n",
      "   - 50th percentile: 16\n",
      "   - 75th percentile: 23\n",
      "   - Max: 31\n",
      "\n",
      "2. **mnth (integer)**:\n",
      "   - Count: 731\n",
      "   - Mean: 6.52\n",
      "   - Std: 3.45\n",
      "   - Min: 1\n",
      "   - 25th percentile: 4\n",
      "   - 50th percentile: 7\n",
      "   - 75th percentile: 10\n",
      "   - Max: 12\n",
      "\n",
      "3. **year (integer)**:\n",
      "   - Count: 731\n",
      "   - Mean: 2011.50\n",
      "   - Std: 0.50\n",
      "   - Min: 2011\n",
      "   - 25th percentile: 2011\n",
      "   - 50th percentile: 2012\n",
      "   - 75th percentile: 2012\n",
      "   - Max: 2012\n",
      "\n",
      "4. **season (integer)**:\n",
      "   - Count: 731\n",
      "   - Mean: 2.50\n",
      "   - Std: 1.11\n",
      "   - Min: 1\n",
      "   - 25th percentile: 2\n",
      "   - 50th percentile: 3\n",
      "   - 75th percentile: 3\n",
      "   - Max: 4\n",
      "\n",
      "5. **holiday (integer, binary)**:\n",
      "   - Count: 731\n",
      "   - Mean: 0.03\n",
      "   - Std: 0.17\n",
      "   - Min: 0\n",
      "   - 25th percentile: 0\n",
      "   - 50th percentile: 0\n",
      "   - 75th percentile: 0\n",
      "   - Max: 1\n",
      "\n",
      "6. **weekday (integer)**:\n",
      "   - Count: 731\n",
      "   - Mean: 3.00\n",
      "   - Std: 2.00\n",
      "   - Min: 0\n",
      "   - 25th percentile: 1\n",
      "   - 50th percentile: 3\n",
      "   - 75th percentile: 5\n",
      "   - Max: 6\n",
      "\n",
      "7. **workingday (integer, binary)**:\n",
      "   - Count: 731\n",
      "   - Mean: 0.68\n",
      "   - Std: 0.47\n",
      "   - Min: 0\n",
      "   - 25th percentile: 0\n",
      "   - 50th percentile: 1\n",
      "   - 75th percentile: 1\n",
      "   - Max: 1\n",
      "\n",
      "8. **weathersit (integer)**:\n",
      "   - Count: 731\n",
      "   - Mean: 1.40\n",
      "   - Std: 0.54\n",
      "   - Min: 1\n",
      "   - 25th percentile: 1\n",
      "   - 50th percentile: 1\n",
      "   - 75th percentile: 2\n",
      "   - Max: 3\n",
      "\n",
      "9. **temp (float, scaled)**:\n",
      "   - Count: 731\n",
      "   - Mean: 0.50\n",
      "   - Std: 0.18\n",
      "   - Min: 0.06\n",
      "   - 25th percentile: 0.34\n",
      "   - 50th percentile: 0.50\n",
      "   - 75th percentile: 0.66\n",
      "   - Max: 0.86\n",
      "\n",
      "10. **atemp (float, scaled)**:\n",
      "    - Count: 731\n",
      "    - Mean: 0.47\n",
      "    - Std: 0.16\n",
      "    - Min: 0.08\n",
      "    - 25th percentile: 0.34\n",
      "    - 50th percentile: 0.49\n",
      "    - 75th percentile: 0.61\n",
      "    - Max: 0.84\n",
      "\n",
      "11. **hum (float, scaled)**:\n",
      "    - Count: 731\n",
      "    - Mean: 0.63\n",
      "    - Std: 0.14\n",
      "    - Min: 0.00\n",
      "    - 25th percentile: 0.52\n",
      "    - 50th percentile: 0.63\n",
      "    - 75th percentile: 0.73\n",
      "    - Max: 0.97\n",
      "\n",
      "12. **windspeed (float, scaled)**:\n",
      "    - Count: 731\n",
      "    - Mean: 0.19\n",
      "    - Std: 0.08\n",
      "    - Min: 0.02\n",
      "    - 25th percentile: 0.13\n",
      "    - 50th percentile: 0.18\n",
      "    - 75th percentile: 0.23\n",
      "    - Max: 0.51\n",
      "\n",
      "13. **rentals (integer)**:\n",
      "    - Count: 731\n",
      "    - Mean: 848.18\n",
      "    - Std: 686.62\n",
      "    - Min: 2\n",
      "    - 25th percentile: 315.50\n",
      "    - 50th percentile: 713\n",
      "    - 75th percentile: 1096\n",
      "    - Max: 3410\n",
      "\n",
      "Would you like any specific analysis or visualization from this data?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=updated_thread.id,\n",
    "    assistant_id=thread_assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Results from files in Assistants and Threads\n",
    "\n",
    "Let's see what happens if we use an assistant with a file and a thread with a file together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_HCO2Yi5dpRHtQm4x0lLNhIgs', created_at=1717720503, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "super_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a summary of the penguins-size.csv and daily-bike-share.csv files.\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(super_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_HCO2Yi5dpRHtQm4x0lLNhIgs', created_at=1717720503, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['file-ja8z169Xf9X5mU248naSSheD']), file_search=None))\n"
     ]
    }
   ],
   "source": [
    "super_updated_thread = client.beta.threads.update(\n",
    "    thread_id=super_thread.id,\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [thread_file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(super_updated_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT MESSAGE >\n",
      "code_interpreter\n",
      "\n",
      "\n",
      "ASSISTANT MESSAGE >\n",
      "### penguins-size.csv Summary\n",
      "\n",
      "**Statistics:**\n",
      "- **species**: 344 entries; species include 'Adelie', 'Chinstrap', and 'Gentoo'.\n",
      "- **island**: 344 entries; islands include 'Biscoe', 'Dream', and 'Torgersen'.\n",
      "- **culmen_length_mm**: 342 non-null entries, mean of 43.92 mm, ranging from 32.1 to 59.6 mm.\n",
      "- **culmen_depth_mm**: 342 non-null entries, mean of 17.15 mm, ranging from 13.1 to 21.5 mm.\n",
      "- **flipper_length_mm**: 342 non-null entries, mean of 200.92 mm, ranging from 172 to 231 mm.\n",
      "- **body_mass_g**: 342 non-null entries, mean of 4201.75 g, ranging from 2700 to 6300 g.\n",
      "- **sex**: 334 non-null entries; categories are MALE and FEMALE.\n",
      "\n",
      "**First Few Rows:**\n",
      "| species | island    | culmen_length_mm | culmen_depth_mm | flipper_length_mm | body_mass_g | sex    |\n",
      "|---------|-----------|------------------|-----------------|-------------------|-------------|--------|\n",
      "| Adelie  | Torgersen | 39.1             | 18.7            | 181.0             | 3750.0      | MALE   |\n",
      "| Adelie  | Torgersen | 39.5             | 17.4            | 186.0             | 3800.0      | FEMALE |\n",
      "| Adelie  | Torgersen | 40.3             | 18.0            | 195.0             | 3250.0      | FEMALE |\n",
      "| Adelie  | Torgersen | NaN              | NaN             | NaN               | NaN         | NaN    |\n",
      "| Adelie  | Torgersen | 36.7             | 19.3            | 193.0             | 3450.0      | FEMALE |\n",
      "\n",
      "### daily-bike-share.csv Summary\n",
      "\n",
      "**Statistics:**\n",
      "- **day**: Day of the month (1-31)\n",
      "- **mnth**: Month (1-12)\n",
      "- **year**: Year (2011-2012)\n",
      "- **season**: Season (1-4)\n",
      "- **holiday**: Whether it's a holiday (0 or 1)\n",
      "- **weekday**: Day of the week (0-6)\n",
      "- **workingday**: Working day (0 or 1)\n",
      "- **weathersit**: Weather situation (1-3)\n",
      "- **temp**: Normalized temperature, mean of 0.495\n",
      "- **atemp**: Normalized feeling temperature, mean of 0.474\n",
      "- **hum**: Normalized humidity, mean of 0.628\n",
      "- **windspeed**: Normalized wind speed, mean of 0.190\n",
      "- **rentals**: Count of bike rentals, mean of 848.18, ranging from 2 to 3,410\n",
      "\n",
      "**First Few Rows:**\n",
      "| day | mnth | year | season | holiday | weekday | workingday | weathersit | temp     | atemp    | hum      | windspeed | rentals |\n",
      "|-----|------|------|--------|---------|---------|------------|------------|----------|----------|----------|-----------|---------|\n",
      "| 1   | 1    | 2011 | 1      | 0       | 6       | 0          | 2          | 0.344167 | 0.363625 | 0.805833 | 0.160446  | 331     |\n",
      "| 2   | 1    | 2011 | 1      | 0       | 0       | 0          | 2          | 0.363478 | 0.353739 | 0.696087 | 0.248539  | 131     |\n",
      "| 3   | 1    | 2011 | 1      | 0       | 1       | 1          | 1          | 0.196364 | 0.189405 | 0.437273 | 0.248309  | 120     |\n",
      "| 4   | 1    | 2011 | 1      | 0       | 2       | 1          | 1          | 0.200000 | 0.212122 | 0.590435 | 0.160296  | 108     |\n",
      "| 5   | 1    | 2011 | 1      | 0       | 3       | 1          | 1          | 0.226957 | 0.229270 | 0.436957 | 0.186900  | 82      |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stream the output from the assistant\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=super_updated_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Results Output\n",
    "\n",
    "We may have other things that are produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"thread_DvnJkhiUKl6rtR6gI8SQu5XD\",\n",
      "  \"created_at\": 1717759497,\n",
      "  \"metadata\": {},\n",
      "  \"object\": \"thread\",\n",
      "  \"tool_resources\": {\n",
      "    \"code_interpreter\": {\n",
      "      \"file_ids\": [\n",
      "        \"file-mnBlQQ2gtHTHA3o3tztpCXzv\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\"./artifacts/penguins_size.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create the assistant with the Code Interpreter tool\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data analyst. When provided with a file, analyze the data and generate visualizations.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a thread to start the analysis\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please analyze the data in the uploaded file and generate relevant visualizations.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fetch the results of the analysis\n",
    "response = client.beta.threads.retrieve(thread.id)\n",
    "\n",
    "# Convert the response to a dictionary to access its attributes\n",
    "response_dict = response.to_dict()\n",
    "\n",
    "# Debug: Print the entire response to understand its structure\n",
    "print(json.dumps(response_dict, indent=2))\n",
    "\n",
    "# Access messages from the thread\n",
    "messages = response_dict.get('messages', [])\n",
    "for message in messages:\n",
    "    content = message.get('content', '')\n",
    "    print(content)\n",
    "    \n",
    "    # If the response includes images, download and save them\n",
    "    if \"image_file\" in message:\n",
    "        image_file_id = message[\"image_file\"][\"file_id\"]\n",
    "        image_data = client.files.content(image_file_id)\n",
    "        with open(\"analysis_image.png\", \"wb\") as image_file:\n",
    "            image_file.write(image_data.read())\n",
    "        # Display the image in the notebook\n",
    "        display(Image(\"analysis_image.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
